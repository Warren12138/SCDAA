{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "from lib.Exercise1_1 import LQRSolver\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time \n",
    "\n",
    "Proj_dtype = torch.double\n",
    "Proj_device = 'cpu' \n",
    "class DGMNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DGMNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(3, 100)  \n",
    "        self.layer2 = nn.Linear(100, 100)\n",
    "        self.layer3 = nn.Linear(100, 100)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.tanh(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "\n",
    "        return self.output(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hessian(grad,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad[i])):\n",
    "            u_xxi = torch.autograd.grad(grad[i][j], x, grad_outputs=torch.ones_like(grad[i][j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi[i].unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "        #print(Hessian)\n",
    "    return Hessian\n",
    "\n",
    "def get_hessian_(model,t,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    for i in range(len(t)):\n",
    "        x_i = V(x[i],requires_grad=True)\n",
    "        input = torch.cat(((t[i]).unsqueeze(0), x_i),dim=0)\n",
    "        u_in = model(input)\n",
    "        grad = torch.autograd.grad(u_in, x_i, grad_outputs=torch.ones_like(u_in), create_graph=True, retain_graph=True)[0]\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad)):\n",
    "            u_xxi = torch.autograd.grad(grad[j], x_i, grad_outputs=torch.ones_like(grad[j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi.unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "    return Hessian\n",
    "\n",
    "def pde_residual(model, t, x):\n",
    "    \n",
    "    input = torch.cat((t.unsqueeze(1), x),dim=1)\n",
    "    \n",
    "    u = model(input)\n",
    "\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    u_xx = get_hessian(u_x,x)\n",
    "\n",
    "#    u_xx = get_hessian_(model,t,x)\n",
    " \n",
    "    residual = u_t + 0.5 * torch.einsum('bii->b', sigma @ sigma.transpose(1,2) @ u_xx) + (u_x.unsqueeze(1) @ (H @ x.unsqueeze(1).transpose(1,2)) + u_x.unsqueeze(1) @ M @ alpha + x.unsqueeze(1) @ C @ x.unsqueeze(1).transpose(1,2) + alpha.transpose(1,2) @ D @ alpha).squeeze()\n",
    "    return residual\n",
    "\n",
    "def boundary_condition(model,t, x):\n",
    "\n",
    "    \n",
    "    T_input = T * torch.ones_like(t)\n",
    "\n",
    "    input = torch.cat((T_input.unsqueeze(1), x),dim=1)\n",
    "    u = model(input)\n",
    "\n",
    "    return u - (x.unsqueeze(1) @ R @ x.unsqueeze(1).transpose(1,2)).squeeze()\n",
    "\n",
    "def total_residual(model, t, x):\n",
    "    # 计算内部PDE残差\n",
    "    residual_loss = pde_residual(model, t, x).pow(2).mean()\n",
    "    # 计算边界条件的残差\n",
    "    boundary_loss = boundary_condition(model,t,x).pow(2).mean()\n",
    "    \n",
    "    return residual_loss + boundary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_data(num_samples):\n",
    "    #num_samples = 10000\n",
    "    t_samples = T * torch.rand(num_samples, dtype=Proj_dtype, device = Proj_device, requires_grad=True)\n",
    "    x_ends = torch.tensor([-3,3], dtype = Proj_dtype)\n",
    "    x_samples = x_ends[0] + (x_ends[1]- x_ends[0]) * torch.rand(num_samples , 2, dtype=Proj_dtype, device = Proj_device, requires_grad=True)\n",
    "    return t_samples,x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrices for LQR problem\n",
    "H = torch.tensor([[1.2, 0.8], [-0.6, 0.9]], dtype=Proj_dtype, device = Proj_device)\n",
    "M = torch.tensor([[0.5,0.7], [0.3,1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "sigma = torch.tensor([[[0.8],[1.1]]], dtype=Proj_dtype, device = Proj_device)\n",
    "alpha = torch.tensor([[[1],[1]]], dtype=Proj_dtype, device = Proj_device)\n",
    "C = torch.tensor([[1.6, 0.0], [0.0, 1.1]], dtype=Proj_dtype, device = Proj_device)\n",
    "D = torch.tensor([[0.5, 0.0], [0.0, 0.7]], dtype=Proj_dtype, device = Proj_device)\n",
    "R = torch.tensor([[0.9, 0.0], [0.0, 1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "T = torch.tensor(1.0, dtype=Proj_dtype, device = Proj_device)\n",
    "\n",
    "solver = LQRSolver(H, M, sigma, C, D, R, T=T, method=\"euler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/5\n",
      "\n",
      "Epoch 1/1000 \t Loss: 151.23439737917408\n",
      "Epoch 50/1000 \t Loss: 14.607246259430346\n"
     ]
    }
   ],
   "source": [
    "model_DGM = DGMNN().double()\n",
    "#model_DGM = DGMNN().float().to(Proj_device)\n",
    "# Prepare for training\n",
    "optimizer_DGM = torch.optim.Adam(model_DGM.parameters(), lr=0.001)\n",
    "epoch_losses = []\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 100\n",
    "\n",
    "for batch in range(batch_size):\n",
    "  \n",
    "    print(f'Batch {batch+1}/{batch_size}'+'\\n')\n",
    "    \n",
    "    t_data,x_data = new_data(5000)\n",
    "    dataset = TensorDataset(t_data,x_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model_DGM.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (t_data_,x_data_) in enumerate(dataloader):\n",
    "            optimizer_DGM.zero_grad()\n",
    "            t_v = V(t_data_,requires_grad=True)\n",
    "            x_v = V(x_data_,requires_grad=True)\n",
    "            loss = total_residual(model_DGM, t_v, x_v) \n",
    "            loss.backward(retain_graph=False)\n",
    "            #loss.backward(retain_graph=True)\n",
    "            optimizer_DGM.step()\n",
    "            total_loss += loss.item()\n",
    "        epoch_losses.append(total_loss / len(dataloader))\n",
    "\n",
    "        if epoch == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} \\t Loss: {total_loss / len(dataloader)}')\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} \\t Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "    print('\\n')\n",
    "model_DGM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "t_data,x_data = new_data(5)\n",
    "\n",
    "value_numerical = solver.value_function(t_data.detach(),x_data.detach().unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model_DGM(torch.cat((t_data.unsqueeze(1), x_data.squeeze(1)),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_numerical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
