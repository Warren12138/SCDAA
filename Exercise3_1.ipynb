{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "from lib.Exercise1_1 import LQRSolver\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time \n",
    "\n",
    "Proj_dtype = torch.double\n",
    "Proj_device = 'cpu' \n",
    "class DGMNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DGMNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(3, 100)  \n",
    "        self.layer2 = nn.Linear(100, 100)\n",
    "        self.layer3 = nn.Linear(100, 100)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.tanh(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "\n",
    "        return self.output(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGMNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DGMNN2, self).__init__()\n",
    "        self.layer1 = nn.Linear(3, 100)\n",
    "        self.layer2 = nn.Linear(100, 100)\n",
    "        self.layer3 = nn.Linear(100, 100)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.relu(self.layer1(x))\n",
    "        identity = out1\n",
    "        out2 = self.tanh(self.layer2(out1)+identity)\n",
    "        identity = out2\n",
    "        out3 = self.relu(self.layer3(out2)+identity)\n",
    "        return self.output(out3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hessian(grad,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad[i])):\n",
    "            u_xxi = torch.autograd.grad(grad[i][j], x, grad_outputs=torch.ones_like(grad[i][j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi[i].unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "        #print(Hessian)\n",
    "    return Hessian\n",
    "\n",
    "def get_hessian_(model,t,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    for i in range(len(t)):\n",
    "        x_i = V(x[i],requires_grad=True)\n",
    "        input = torch.cat(((t[i]).unsqueeze(0), x_i),dim=0)\n",
    "        u_in = model(input)\n",
    "        grad = torch.autograd.grad(u_in, x_i, grad_outputs=torch.ones_like(u_in), create_graph=True, retain_graph=True)[0]\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad)):\n",
    "            u_xxi = torch.autograd.grad(grad[j], x_i, grad_outputs=torch.ones_like(grad[j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi.unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "    return Hessian\n",
    "\n",
    "def pde_residual(model, t, x):\n",
    "    \n",
    "    input = torch.cat((t.unsqueeze(1), x),dim=1)\n",
    "    \n",
    "    u = model(input)\n",
    "\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    u_xx = get_hessian(u_x,x)\n",
    "\n",
    "#    u_xx = get_hessian_(model,t,x)\n",
    " \n",
    "    residual = u_t + 0.5 * torch.einsum('bii->b', sigma @ sigma.transpose(1,2) @ u_xx) + (u_x.unsqueeze(1) @ (H @ x.unsqueeze(1).transpose(1,2)) + u_x.unsqueeze(1) @ M @ alpha + x.unsqueeze(1) @ C @ x.unsqueeze(1).transpose(1,2) + alpha.transpose(1,2) @ D @ alpha).squeeze()\n",
    "    return residual\n",
    "\n",
    "def boundary_condition(model,t, x):\n",
    "\n",
    "    \n",
    "    T_input = T * torch.ones_like(t)\n",
    "\n",
    "    input = torch.cat((T_input.unsqueeze(1), x),dim=1)\n",
    "    u = model(input)\n",
    "\n",
    "    return u - (x.unsqueeze(1) @ R @ x.unsqueeze(1).transpose(1,2)).squeeze()\n",
    "\n",
    "def total_residual(model, t, x):\n",
    "    \n",
    "    residual_loss = pde_residual(model, t, x).pow(2).mean()\n",
    "    boundary_loss = boundary_condition(model,t,x).pow(2).mean()\n",
    "    \n",
    "    return residual_loss + boundary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_data(num_samples):\n",
    "    #num_samples = 10000\n",
    "    t_samples = T * torch.rand(num_samples, dtype=Proj_dtype, device = Proj_device, requires_grad=True)\n",
    "    x_ends = torch.tensor([-3,3], dtype = Proj_dtype)\n",
    "    x_samples = x_ends[0] + (x_ends[1]- x_ends[0]) * torch.rand(num_samples , 2, dtype=Proj_dtype, device = Proj_device, requires_grad=True)\n",
    "    return t_samples,x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrices for LQR problem\n",
    "\n",
    "H = torch.tensor([[1.2, 0.8], [-0.6, 0.9]], dtype=Proj_dtype, device = Proj_device)\n",
    "M = torch.tensor([[0.5,0.7], [0.3,1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "sigma = torch.tensor([[[0.08],[0.11]]], dtype=Proj_dtype, device = Proj_device)\n",
    "alpha = torch.tensor([[[1],[1]]], dtype=Proj_dtype, device = Proj_device)\n",
    "C = torch.tensor([[1.6, 0.0], [0.0, 1.1]], dtype=Proj_dtype, device = Proj_device)\n",
    "D = torch.tensor([[0.5, 0.0], [0.0, 0.7]], dtype=Proj_dtype, device = Proj_device)\n",
    "R = torch.tensor([[0.9, 0.0], [0.0, 1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "T = torch.tensor(1.0, dtype=Proj_dtype, device = Proj_device)\n",
    "\n",
    "solver = LQRSolver(H, M, sigma, C, D, R, T=T, method=\"euler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/5\n",
      "\n",
      "Epoch 1/40 \t Loss: 22.0448031758185\n",
      "Epoch 5/40 \t Loss: 14.071662692119485\n",
      "Epoch 10/40 \t Loss: 13.585069977812214\n",
      "Epoch 15/40 \t Loss: 13.611596094140328\n",
      "Epoch 20/40 \t Loss: 13.538291309865443\n",
      "Epoch 25/40 \t Loss: 13.495876072534461\n",
      "Epoch 30/40 \t Loss: 13.448839961618884\n",
      "Epoch 35/40 \t Loss: 13.415517450749325\n",
      "Epoch 40/40 \t Loss: 13.41442112290959\n",
      "\n",
      "\n",
      "Batch 2/5\n",
      "\n",
      "Epoch 1/40 \t Loss: 13.67024971258974\n",
      "Epoch 5/40 \t Loss: 13.65172014535303\n",
      "Epoch 10/40 \t Loss: 13.628008308581908\n",
      "Epoch 15/40 \t Loss: 13.633298935806014\n",
      "Epoch 20/40 \t Loss: 13.630270187637356\n",
      "Epoch 25/40 \t Loss: 13.66529995146322\n",
      "Epoch 30/40 \t Loss: 13.619505628173902\n",
      "Epoch 35/40 \t Loss: 13.61495655881156\n",
      "Epoch 40/40 \t Loss: 13.60173320851126\n",
      "\n",
      "\n",
      "Batch 3/5\n",
      "\n",
      "Epoch 1/40 \t Loss: 13.298605003150703\n",
      "Epoch 5/40 \t Loss: 13.270565216561035\n",
      "Epoch 10/40 \t Loss: 13.266231258176798\n",
      "Epoch 15/40 \t Loss: 13.257727373498696\n",
      "Epoch 20/40 \t Loss: 13.26053464010837\n",
      "Epoch 25/40 \t Loss: 13.284311212937805\n",
      "Epoch 30/40 \t Loss: 13.278249826343153\n",
      "Epoch 35/40 \t Loss: 13.284128446135558\n",
      "Epoch 40/40 \t Loss: 13.286364109355034\n",
      "\n",
      "\n",
      "Batch 4/5\n",
      "\n",
      "Epoch 1/40 \t Loss: 13.156863963178262\n",
      "Epoch 5/40 \t Loss: 13.182260928279366\n",
      "Epoch 10/40 \t Loss: 13.152778283967063\n",
      "Epoch 15/40 \t Loss: 13.156005837006365\n",
      "Epoch 20/40 \t Loss: 13.147448797360104\n",
      "Epoch 25/40 \t Loss: 13.17512525746358\n",
      "Epoch 30/40 \t Loss: 13.200415985739753\n",
      "Epoch 35/40 \t Loss: 13.153690618070723\n",
      "Epoch 40/40 \t Loss: 13.149249217633805\n",
      "\n",
      "\n",
      "Batch 5/5\n",
      "\n",
      "Epoch 1/40 \t Loss: 13.317031005421473\n",
      "Epoch 5/40 \t Loss: 13.299119815916995\n",
      "Epoch 10/40 \t Loss: 13.310563125350228\n",
      "Epoch 15/40 \t Loss: 13.329161571308571\n",
      "Epoch 20/40 \t Loss: 13.298508116038107\n",
      "Epoch 25/40 \t Loss: 13.316602963799477\n",
      "Epoch 30/40 \t Loss: 13.32376298987982\n",
      "Epoch 35/40 \t Loss: 13.336705035420426\n",
      "Epoch 40/40 \t Loss: 13.328619290291948\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DGMNN2(\n",
       "  (layer1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (layer2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (layer3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (relu): ReLU()\n",
       "  (output): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DGM = DGMNN2().double()\n",
    "stat_dict = torch.load('model2_DGM_state_dict.pt', map_location=torch.device('cpu'))\n",
    "model_DGM.load_state_dict(stat_dict)\n",
    "#model_DGM = DGMNN().float().to(Proj_device)\n",
    "# Prepare for training\n",
    "optimizer_DGM = torch.optim.Adam(model_DGM.parameters(), lr=0.01)\n",
    "scheduler_DGM = lr_scheduler.ExponentialLR(optimizer_DGM, gamma=0.9)\n",
    "epoch_losses = []\n",
    "\n",
    "Batch_size = 5\n",
    "epochs = 40\n",
    "\n",
    "for batch in range(Batch_size):\n",
    "  \n",
    "    print(f'Batch {batch+1}/{Batch_size}'+'\\n')\n",
    "    \n",
    "    t_data,x_data = new_data(5000)\n",
    "    dataset = TensorDataset(t_data,x_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model_DGM.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (t_data_,x_data_) in enumerate(dataloader):\n",
    "            optimizer_DGM.zero_grad()\n",
    "            t_v = V(t_data_,requires_grad=True)\n",
    "            x_v = V(x_data_,requires_grad=True)\n",
    "            loss = total_residual(model_DGM, t_v, x_v) \n",
    "            loss.backward(retain_graph=False)\n",
    "            #loss.backward(retain_graph=True)\n",
    "            optimizer_DGM.step()\n",
    "            total_loss += loss.item()\n",
    "        epoch_losses.append(total_loss / len(dataloader))\n",
    "        \n",
    "        scheduler_DGM.step()\n",
    "        if epoch == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} \\t Loss: {total_loss / len(dataloader)}')\n",
    "        if(epoch+1)% 10 == 0:\n",
    "            torch.save(model_DGM.state_dict(), 'model2_DGM_state_dict.pt')\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} \\t Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "    print('\\n')\n",
    "model_DGM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_interval_setting = torch.load('Exercise3/value_numerical/3x3/'+'interval_setting.pt')\n",
    "t_ends = load_interval_setting['t_ends']\n",
    "t_num = load_interval_setting['t_num']\n",
    "x_ends = load_interval_setting['x_ends']\n",
    "x_num = load_interval_setting['x_num']\n",
    "\n",
    "# Establish meshgrid structure from setting.\n",
    "\n",
    "t_batch_i = torch.linspace(t_ends[0],t_ends[1],t_num,dtype=torch.double)\n",
    "t_batch = t_batch_i.repeat_interleave(x_num[0]*x_num[1])\n",
    "\n",
    "x1 = torch.linspace(x_ends[0][0],x_ends[0][1],x_num[0],dtype=torch.double)\n",
    "x2 = torch.linspace(x_ends[1][0],x_ends[1][1],x_num[1],dtype=torch.double)\n",
    "\n",
    "x_batch = torch.cartesian_prod(x1, x2).unsqueeze(1).repeat(t_num, 1, 1)\n",
    "\n",
    "x_batch_i = torch.cartesian_prod(x1, x2).unsqueeze(1)\n",
    "\n",
    "X1 = x_batch_i[:, 0, 0].view(x_num[0], x_num[1])\n",
    "X2 = x_batch_i[:, 0, 1].view(x_num[0], x_num[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path_MC_FSS = 'Exercise3'+ '/' + f'value_MC/{x_num[0]}x{x_num[1]}/FSS_1e5'\n",
    "\n",
    "FSS_VTSN = [int(x) for x in[5e3]]\n",
    "\n",
    "MSE_FSS_VTSN = []\n",
    "J = []\n",
    "for i in FSS_VTSN:\n",
    "    if i == 1:\n",
    "        trvlthg = ''\n",
    "    else:\n",
    "        trvlthg = 's'\n",
    "    path_FSS_VTSN_i = f\"{file_path_MC_FSS}/{i}_step{trvlthg}\"\n",
    "\n",
    "    J_load_test = torch.load(path_FSS_VTSN_i + '/value_MC.pt')\n",
    "    \n",
    "    J_processed,_ = torch.min(J_load_test,dim = 1)\n",
    "\n",
    "    J.append(J_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.3017e+04, 2.3263e+03, 5.1811e+02, 4.4414e+03, 3.0043e+00, 4.4438e+03,\n",
       "         5.1807e+02, 2.3284e+03, 1.3023e+04, 6.4233e+03, 1.1970e+03, 2.8020e+02,\n",
       "         2.1580e+03, 1.9030e+00, 2.1573e+03, 2.8078e+02, 1.1973e+03, 6.4229e+03,\n",
       "         3.1621e+03, 6.2128e+02, 1.6471e+02, 1.0424e+03, 1.2883e+00, 1.0420e+03,\n",
       "         1.6474e+02, 6.2202e+02, 3.1622e+03, 1.5508e+03, 3.2614e+02, 1.0586e+02,\n",
       "         5.0345e+02, 9.3517e-01, 5.0310e+02, 1.0581e+02, 3.2611e+02, 1.5509e+03,\n",
       "         7.5768e+02, 1.7330e+02, 7.3826e+01, 2.4318e+02, 7.0335e-01, 2.4313e+02,\n",
       "         7.3837e+01, 1.7329e+02, 7.5778e+02, 3.6838e+02, 9.3428e+01, 5.4422e+01,\n",
       "         1.1848e+02, 5.2839e-01, 1.1849e+02, 5.4438e+01, 9.3441e+01, 3.6838e+02,\n",
       "         1.7743e+02, 5.0974e+01, 4.1271e+01, 5.8761e+01, 3.8132e-01, 5.8735e+01,\n",
       "         4.1279e+01, 5.0971e+01, 1.7738e+02, 8.4289e+01, 2.8008e+01, 3.1423e+01,\n",
       "         3.0081e+01, 2.4854e-01, 3.0077e+01, 3.1427e+01, 2.8018e+01, 8.4262e+01,\n",
       "         3.9005e+01, 1.5326e+01, 2.3572e+01, 1.6088e+01, 1.2278e-01, 1.6085e+01,\n",
       "         2.3573e+01, 1.5324e+01, 3.9017e+01], dtype=torch.float64)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.4420, 15.4490,  9.3243, 17.8923,  9.3380, 11.3787, 13.3540, 11.6964,\n",
       "         7.2905, 14.0925, 14.6957,  8.7488, 16.3328,  8.7053, 10.9480, 12.1048,\n",
       "        10.8801,  7.1401, 12.8142, 13.8359,  8.1622, 14.8462,  8.0783, 10.5105,\n",
       "        10.9401, 10.1062,  6.9548, 11.5975, 12.8827,  7.5455, 13.3848,  7.4557,\n",
       "        10.0324,  9.8203,  9.3598,  6.7470, 10.4355, 11.7823,  6.9146, 11.9831,\n",
       "         6.8559,  9.5029,  8.7341,  8.6242,  6.4242,  9.2421, 10.6038,  6.2761,\n",
       "        10.6367,  6.4843,  8.9168,  7.6693,  7.8969,  6.0483,  7.9966,  9.3562,\n",
       "         5.5693,  9.3934,  6.1552,  8.2874,  6.5904,  7.1690,  5.6146,  6.7441,\n",
       "         8.1041,  4.8405,  8.1606,  5.8692,  7.5470,  5.5409,  6.4444,  5.1182,\n",
       "         5.4942,  6.7311,  4.0966,  7.0207,  5.6070,  6.6686,  4.4892,  5.7129,\n",
       "         4.5791], dtype=torch.float64, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data = t_batch\n",
    "x_data = x_batch.squeeze(1)\n",
    "model_DGM(torch.cat((t_data.unsqueeze(1), x_data),dim=1)).squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
