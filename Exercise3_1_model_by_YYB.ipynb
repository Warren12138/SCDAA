{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from lib.Exercise1_1 import LQRSolver\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time \n",
    "\n",
    "Proj_dtype = torch.double\n",
    "Proj_device = 'cpu' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGMhiddenlayerYYBver(nn.Module):\n",
    "\n",
    "    # From the original paper of Justin's, presented by Yuebo Yang Apr.9th 2024\n",
    "    \n",
    "    def __init__(self, input_f, output_f, activation = 'tanh'):\n",
    "        \n",
    "        super(DGMhiddenlayerYYBver, self).__init__()\n",
    "\n",
    "        self.input_f = input_f\n",
    "        self.output_f = output_f\n",
    "\n",
    "        # Params\n",
    "\n",
    "        # Zl's\n",
    "\n",
    "        self.Uzl = nn.Parameter(torch.Tensor(output_f, input_f))\n",
    "        self.Wzl = nn.Parameter(torch.Tensor(output_f, output_f))\n",
    "        self.bzl = nn.Parameter(torch.Tensor(output_f))\n",
    "\n",
    "        # Gl's\n",
    "\n",
    "        self.Ugl = nn.Parameter(torch.Tensor(output_f, input_f))\n",
    "        self.Wgl = nn.Parameter(torch.Tensor(output_f, output_f))\n",
    "        self.bgl = nn.Parameter(torch.Tensor(output_f))\n",
    "\n",
    "        # Rl's\n",
    "\n",
    "        self.Url = nn.Parameter(torch.Tensor(output_f, input_f))\n",
    "        self.Wrl = nn.Parameter(torch.Tensor(output_f, output_f))\n",
    "        self.brl = nn.Parameter(torch.Tensor(output_f))\n",
    "\n",
    "        # Hl's\n",
    "\n",
    "        self.Uhl = nn.Parameter(torch.Tensor(output_f, input_f))\n",
    "        self.Whl = nn.Parameter(torch.Tensor(output_f, output_f))\n",
    "        self.bhl = nn.Parameter(torch.Tensor(output_f))\n",
    "\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        else:\n",
    "            self.activation = None \n",
    "\n",
    "        self.init_method = 'normal' # or 'uniform'\n",
    "\n",
    "        self._initialize_params()\n",
    "\n",
    "    def _initialize_params(self):\n",
    "\n",
    "        if self.init_method == 'uniform':\n",
    "            for param in self.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    init.xavier_uniform_(param)  \n",
    "                else:\n",
    "                    init.constant_(param, 0) \n",
    "                    \n",
    "        if self.init_method == 'normal':\n",
    "            for param in self.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    init.xavier_normal_(param)  \n",
    "                else:\n",
    "                    init.constant_(param, 0) \n",
    "\n",
    "    def forward(self, x, S1, Sl):\n",
    "\n",
    "        Zl = self.activation(torch.mm(x, self.Uzl.t())+ torch.mm(Sl, self.Wzl.t()) + self.bzl)\n",
    "\n",
    "        Gl = self.activation(torch.mm(x, self.Ugl.t())+ torch.mm(S1, self.Wgl.t()) + self.bgl)\n",
    "\n",
    "        Rl = self.activation(torch.mm(x, self.Url.t())+ torch.mm(Sl, self.Wrl.t()) + self.brl)\n",
    "\n",
    "        Hl = self.activation(torch.mm(x, self.Uhl.t())+ torch.mm(torch.mul(Sl,Rl), self.Whl.t()) + self.bhl)\n",
    "\n",
    "        Sl_1 = torch.mul((1-Gl),Hl) + torch.mul(Zl,Sl)\n",
    "\n",
    "        return Sl_1\n",
    "\n",
    "\n",
    "class DGMNN_YYBver(nn.Module):\n",
    "\n",
    "    # From the original paper of Justin's, presented by Yuebo Yang Apr.9th 2024\n",
    "\n",
    "    def __init__(self, init_method = 'uniform'):\n",
    "        super(DGMNN_YYBver, self).__init__()\n",
    "\n",
    "        self.nodenum = 50\n",
    "\n",
    "        self.layer1 = DGMhiddenlayerYYBver(3, self.nodenum)\n",
    "        self.layer2 = DGMhiddenlayerYYBver(3, self.nodenum)\n",
    "        self.layer3 = DGMhiddenlayerYYBver(3, self.nodenum)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # Params\n",
    "\n",
    "        # S1's\n",
    "\n",
    "        self.W1 = nn.Parameter(torch.Tensor(self.nodenum, 3))\n",
    "        self.b1 = nn.Parameter(torch.Tensor(self.nodenum))\n",
    "\n",
    "        # Output's\n",
    "\n",
    "        self.W = nn.Parameter(torch.Tensor(1, self.nodenum))\n",
    "        self.b = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        self.activation = torch.tanh\n",
    "\n",
    "        self.init_method = 'normal' # or 'uniform'\n",
    "\n",
    "        self._initialize_params()\n",
    "\n",
    "    def _initialize_params(self):\n",
    "\n",
    "        if self.init_method == 'uniform':\n",
    "            for param in self.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    init.xavier_uniform_(param)  \n",
    "                else:\n",
    "                    init.constant_(param, 0) \n",
    "                    \n",
    "        if self.init_method == 'normal':\n",
    "            for param in self.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    init.xavier_normal_(param)  \n",
    "                else:\n",
    "                    init.constant_(param, 0) \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        S_1 = self.activation(torch.mm(x, self.W1.t()) + self.b1)\n",
    "        # l=1\n",
    "        S_2 = self.layer1(x,S_1,S_1)\n",
    "        # l=2\n",
    "        S_3 = self.layer2(x,S_1,S_2)\n",
    "        # l=3\n",
    "        S_4 = self.layer3(x,S_1,S_3)\n",
    "\n",
    "        output = torch.mm(S_4, self.W.t()) + self.b\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hessian(grad,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad[i])):\n",
    "            u_xxi = torch.autograd.grad(grad[i][j], x, grad_outputs=torch.ones_like(grad[i][j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi[i].unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "        # print(Hessian)\n",
    "    return Hessian\n",
    "\n",
    "def get_hessian_(model,t,x):\n",
    "    Hessian = torch.tensor([], device = Proj_device)\n",
    "    for i in range(len(t)):\n",
    "        x_i = V(x[i],requires_grad=True)\n",
    "        input = torch.cat(((t[i]).unsqueeze(0), x_i),dim=0)\n",
    "        u_in = model(input)\n",
    "        grad = torch.autograd.grad(u_in, x_i, grad_outputs=torch.ones_like(u_in), create_graph=True, retain_graph=True)[0]\n",
    "        hessian = torch.tensor([], device = Proj_device)\n",
    "        for j in range(len(grad)):\n",
    "            u_xxi = torch.autograd.grad(grad[j], x_i, grad_outputs=torch.ones_like(grad[j]), retain_graph=True,create_graph=True, allow_unused=True)[0]           \n",
    "            hessian = torch.cat((hessian, u_xxi.unsqueeze(0)))\n",
    "        Hessian = torch.cat((Hessian, hessian.unsqueeze(0)),dim = 0)\n",
    "    return Hessian\n",
    "\n",
    "def pde_residual(model, t, x):\n",
    "    \n",
    "    input = torch.cat((t.unsqueeze(1), x),dim=1)\n",
    "    \n",
    "    u = model(input)\n",
    "\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    u_xx = get_hessian(u_x,x)\n",
    "\n",
    "#    u_xx = get_hessian_(model,t,x)\n",
    "    \n",
    "    residual = u_t + 0.5 * torch.einsum('bii->b', sigma @ sigma.transpose(1,2) @ u_xx) + (u_x.unsqueeze(1) @ (H @ x.unsqueeze(1).transpose(1,2)) + u_x.unsqueeze(1) @ M @ alpha + x.unsqueeze(1) @ C @ x.unsqueeze(1).transpose(1,2) + alpha.transpose(1,2) @ D @ alpha).squeeze()\n",
    "    \n",
    "    return residual\n",
    "\n",
    "def boundary_condition(model,t,x):\n",
    "\n",
    "    \n",
    "    T_input = T * torch.ones_like(t)\n",
    "\n",
    "    input = torch.cat((T_input.unsqueeze(1), x),dim=1)\n",
    "    u = model(input)\n",
    "\n",
    "    return u - (x.unsqueeze(1) @ R @ x.unsqueeze(1).transpose(1,2)).squeeze()\n",
    "\n",
    "def total_residual(model, t, x):\n",
    "    \n",
    "    residual_loss = pde_residual(model, t, x).pow(2).mean()\n",
    "    boundary_loss = boundary_condition(model,t,x).pow(2).mean()\n",
    "    \n",
    "    return residual_loss + boundary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_data(num_samples):\n",
    "    # num_samples = 10000\n",
    "    t_samples = T * torch.rand(num_samples, dtype=Proj_dtype, device = Proj_device, requires_grad=False)\n",
    "    x_ends = torch.tensor([-3,3], dtype = Proj_dtype)\n",
    "    x_samples = x_ends[0] + (x_ends[1]- x_ends[0]) * torch.rand(num_samples , 2, dtype=Proj_dtype, device = Proj_device, requires_grad=False)\n",
    "    return t_samples,x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrices for LQR problem\n",
    "\n",
    "H = torch.tensor([[1.2, 0.8], [-0.6, 0.9]], dtype=Proj_dtype, device = Proj_device)\n",
    "M = torch.tensor([[0.5,0.7], [0.3,1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "sigma = torch.tensor([[[0.08],[0.11]]], dtype=Proj_dtype, device = Proj_device)\n",
    "alpha = torch.tensor([[[1],[1]]], dtype=Proj_dtype, device = Proj_device)\n",
    "C = torch.tensor([[1.6, 0.0], [0.0, 1.1]], dtype=Proj_dtype, device = Proj_device)\n",
    "D = torch.tensor([[0.5, 0.0], [0.0, 0.7]], dtype=Proj_dtype, device = Proj_device)\n",
    "R = torch.tensor([[0.9, 0.0], [0.0, 1.0]], dtype=Proj_dtype, device = Proj_device)\n",
    "T = torch.tensor(1.0, dtype=Proj_dtype, device = Proj_device)\n",
    "\n",
    "solver = LQRSolver(H, M, sigma, C, D, R, T=T, method=\"euler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/50\n",
      "\n",
      "Epoch 1/100 \t Loss: 163.72832799168555\n",
      "Epoch 5/100 \t Loss: 152.93062884584373\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m t_data \u001b[38;5;241m=\u001b[39m _t_data\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m x_data \u001b[38;5;241m=\u001b[39m _x_data\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_residual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_DGM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#loss.backward(retain_graph=True)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mtotal_residual\u001b[0;34m(model, t, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtotal_residual\u001b[39m(model, t, x):\n\u001b[0;32m---> 56\u001b[0m     residual_loss \u001b[38;5;241m=\u001b[39m \u001b[43mpde_residual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     57\u001b[0m     boundary_loss \u001b[38;5;241m=\u001b[39m boundary_condition(model,t,x)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual_loss \u001b[38;5;241m+\u001b[39m boundary_loss\n",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m, in \u001b[0;36mpde_residual\u001b[0;34m(model, t, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     u_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u, t, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m     u_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u, x, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 36\u001b[0m     u_xx \u001b[38;5;241m=\u001b[39m \u001b[43mget_hessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#    u_xx = get_hessian_(model,t,x)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     residual \u001b[38;5;241m=\u001b[39m u_t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbii->b\u001b[39m\u001b[38;5;124m'\u001b[39m, sigma \u001b[38;5;241m@\u001b[39m sigma\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m u_xx) \u001b[38;5;241m+\u001b[39m (u_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m (H \u001b[38;5;241m@\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m u_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m M \u001b[38;5;241m@\u001b[39m alpha \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m C \u001b[38;5;241m@\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m alpha\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m D \u001b[38;5;241m@\u001b[39m alpha)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mget_hessian\u001b[0;34m(grad, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m hessian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([], device \u001b[38;5;241m=\u001b[39m Proj_device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(grad[i])):\n\u001b[0;32m----> 7\u001b[0m     u_xxi \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]           \n\u001b[1;32m      8\u001b[0m     hessian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((hessian, u_xxi[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m      9\u001b[0m Hessian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((Hessian, hessian\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)),dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Project of Stochastic Control/env_SCDAA/lib/python3.12/site-packages/torch/autograd/__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    408\u001b[0m         grad_outputs_\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    424\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_DGM = DGMNN_YYBver().double()\n",
    "\n",
    "#stat_dict = torch.load('model2_DGM_state_dict.pt', map_location=torch.device('cpu'))\n",
    "#model_DGM.load_state_dict(stat_dict)\n",
    "\n",
    "#model_DGM = DGMNN().float().to(Proj_device)\n",
    "# Prepare for training\n",
    "optimizer_DGM = torch.optim.Adam(model_DGM.parameters(), lr=0.0001)\n",
    "scheduler_DGM = lr_scheduler.ExponentialLR(optimizer_DGM, gamma=0.9)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "iterations = 50\n",
    "epochs = 100\n",
    "\n",
    "patience = 10\n",
    "\n",
    "for iteration in range(iterations):\n",
    "  \n",
    "    print(f'Iteration {iteration+1}/{iterations}'+'\\n')\n",
    "    \n",
    "    t_data,x_data = new_data(1000)\n",
    "    dataset = TensorDataset(t_data,x_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model_DGM.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (_t_data,_x_data) in enumerate(dataloader):\n",
    "            optimizer_DGM.zero_grad()\n",
    "            t_data = _t_data.clone().requires_grad_(True)\n",
    "            x_data = _x_data.clone().requires_grad_(True)\n",
    "            loss = total_residual(model_DGM, t_data, x_data) \n",
    "            loss.backward()\n",
    "            #loss.backward(retain_graph=True)\n",
    "            optimizer_DGM.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        \n",
    "        scheduler_DGM.step()\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0  \n",
    "            \n",
    "            torch.save(model_DGM.state_dict(), 'model_DGM_by_YYB_state_dict.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if epoch == 0 or (epoch+1) % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} \\t Loss: {avg_loss}')\n",
    "        \n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break  \n",
    "    print('\\n')\n",
    "    \n",
    "model_DGM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_interval_setting = torch.load('Exercise3/value_numerical/3x3/'+'interval_setting.pt')\n",
    "t_ends = load_interval_setting['t_ends']\n",
    "t_num = load_interval_setting['t_num']\n",
    "x_ends = load_interval_setting['x_ends']\n",
    "x_num = load_interval_setting['x_num']\n",
    "\n",
    "# Establish meshgrid structure from setting.\n",
    "\n",
    "t_batch_i = torch.linspace(t_ends[0],t_ends[1],t_num,dtype=torch.double)\n",
    "t_batch = t_batch_i.repeat_interleave(x_num[0]*x_num[1])\n",
    "\n",
    "x1 = torch.linspace(x_ends[0][0],x_ends[0][1],x_num[0],dtype=torch.double)\n",
    "x2 = torch.linspace(x_ends[1][0],x_ends[1][1],x_num[1],dtype=torch.double)\n",
    "\n",
    "x_batch = torch.cartesian_prod(x1, x2).unsqueeze(1).repeat(t_num, 1, 1)\n",
    "\n",
    "x_batch_i = torch.cartesian_prod(x1, x2).unsqueeze(1)\n",
    "\n",
    "X1 = x_batch_i[:, 0, 0].view(x_num[0], x_num[1])\n",
    "X2 = x_batch_i[:, 0, 1].view(x_num[0], x_num[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path_MC_FSS = 'Exercise3'+ '/' + f'value_MC/{x_num[0]}x{x_num[1]}/FSS_1e5'\n",
    "\n",
    "FSS_VTSN = [int(x) for x in[5e3]]\n",
    "\n",
    "MSE_FSS_VTSN = []\n",
    "J = []\n",
    "for i in FSS_VTSN:\n",
    "    if i == 1:\n",
    "        trvlthg = ''\n",
    "    else:\n",
    "        trvlthg = 's'\n",
    "    path_FSS_VTSN_i = f\"{file_path_MC_FSS}/{i}_step{trvlthg}\"\n",
    "\n",
    "    J_load_test = torch.load(path_FSS_VTSN_i + '/value_MC.pt')\n",
    "    \n",
    "    J_processed,_ = torch.min(J_load_test,dim = 1)\n",
    "\n",
    "    J.append(J_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3022e+04],\n",
       "        [2.3260e+03],\n",
       "        [5.1761e+02],\n",
       "        [4.4431e+03],\n",
       "        [3.0231e+00],\n",
       "        [4.4433e+03],\n",
       "        [5.1743e+02],\n",
       "        [2.3285e+03],\n",
       "        [1.3022e+04],\n",
       "        [6.4263e+03],\n",
       "        [1.1973e+03],\n",
       "        [2.8039e+02],\n",
       "        [2.1569e+03],\n",
       "        [1.9084e+00],\n",
       "        [2.1566e+03],\n",
       "        [2.8063e+02],\n",
       "        [1.1961e+03],\n",
       "        [6.4246e+03],\n",
       "        [3.1623e+03],\n",
       "        [6.2176e+02],\n",
       "        [1.6450e+02],\n",
       "        [1.0427e+03],\n",
       "        [1.2879e+00],\n",
       "        [1.0421e+03],\n",
       "        [1.6482e+02],\n",
       "        [6.2191e+02],\n",
       "        [3.1619e+03],\n",
       "        [1.5510e+03],\n",
       "        [3.2622e+02],\n",
       "        [1.0589e+02],\n",
       "        [5.0377e+02],\n",
       "        [9.3850e-01],\n",
       "        [5.0333e+02],\n",
       "        [1.0588e+02],\n",
       "        [3.2614e+02],\n",
       "        [1.5510e+03],\n",
       "        [7.5781e+02],\n",
       "        [1.7333e+02],\n",
       "        [7.3801e+01],\n",
       "        [2.4333e+02],\n",
       "        [7.0459e-01],\n",
       "        [2.4318e+02],\n",
       "        [7.3832e+01],\n",
       "        [1.7353e+02],\n",
       "        [7.5829e+02],\n",
       "        [3.6822e+02],\n",
       "        [9.3442e+01],\n",
       "        [5.4428e+01],\n",
       "        [1.1848e+02],\n",
       "        [5.2734e-01],\n",
       "        [1.1839e+02],\n",
       "        [5.4423e+01],\n",
       "        [9.3414e+01],\n",
       "        [3.6840e+02],\n",
       "        [1.7734e+02],\n",
       "        [5.0936e+01],\n",
       "        [4.1271e+01],\n",
       "        [5.8740e+01],\n",
       "        [3.8159e-01],\n",
       "        [5.8750e+01],\n",
       "        [4.1280e+01],\n",
       "        [5.0926e+01],\n",
       "        [1.7747e+02],\n",
       "        [8.4268e+01],\n",
       "        [2.8012e+01],\n",
       "        [3.1420e+01],\n",
       "        [3.0069e+01],\n",
       "        [2.4879e-01],\n",
       "        [3.0085e+01],\n",
       "        [3.1421e+01],\n",
       "        [2.8036e+01],\n",
       "        [8.4240e+01],\n",
       "        [3.9020e+01],\n",
       "        [1.5330e+01],\n",
       "        [2.3571e+01],\n",
       "        [1.6085e+01],\n",
       "        [1.2280e-01],\n",
       "        [1.6086e+01],\n",
       "        [2.3572e+01],\n",
       "        [1.5326e+01],\n",
       "        [3.9010e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_load_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.3017e+04, 2.3263e+03, 5.1811e+02, 4.4414e+03, 3.0043e+00, 4.4438e+03,\n",
       "         5.1807e+02, 2.3284e+03, 1.3023e+04, 6.4233e+03, 1.1970e+03, 2.8020e+02,\n",
       "         2.1580e+03, 1.9030e+00, 2.1573e+03, 2.8078e+02, 1.1973e+03, 6.4229e+03,\n",
       "         3.1621e+03, 6.2128e+02, 1.6471e+02, 1.0424e+03, 1.2883e+00, 1.0420e+03,\n",
       "         1.6474e+02, 6.2202e+02, 3.1622e+03, 1.5508e+03, 3.2614e+02, 1.0586e+02,\n",
       "         5.0345e+02, 9.3517e-01, 5.0310e+02, 1.0581e+02, 3.2611e+02, 1.5509e+03,\n",
       "         7.5768e+02, 1.7330e+02, 7.3826e+01, 2.4318e+02, 7.0335e-01, 2.4313e+02,\n",
       "         7.3837e+01, 1.7329e+02, 7.5778e+02, 3.6838e+02, 9.3428e+01, 5.4422e+01,\n",
       "         1.1848e+02, 5.2839e-01, 1.1849e+02, 5.4438e+01, 9.3441e+01, 3.6838e+02,\n",
       "         1.7743e+02, 5.0974e+01, 4.1271e+01, 5.8761e+01, 3.8132e-01, 5.8735e+01,\n",
       "         4.1279e+01, 5.0971e+01, 1.7738e+02, 8.4289e+01, 2.8008e+01, 3.1423e+01,\n",
       "         3.0081e+01, 2.4854e-01, 3.0077e+01, 3.1427e+01, 2.8018e+01, 8.4262e+01,\n",
       "         3.9005e+01, 1.5326e+01, 2.3572e+01, 1.6088e+01, 1.2278e-01, 1.6085e+01,\n",
       "         2.3573e+01, 1.5324e+01, 3.9017e+01], dtype=torch.float64)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.4420, 15.4490,  9.3243, 17.8923,  9.3380, 11.3787, 13.3540, 11.6964,\n",
       "         7.2905, 14.0925, 14.6957,  8.7488, 16.3328,  8.7053, 10.9480, 12.1048,\n",
       "        10.8801,  7.1401, 12.8142, 13.8359,  8.1622, 14.8462,  8.0783, 10.5105,\n",
       "        10.9401, 10.1062,  6.9548, 11.5975, 12.8827,  7.5455, 13.3848,  7.4557,\n",
       "        10.0324,  9.8203,  9.3598,  6.7470, 10.4355, 11.7823,  6.9146, 11.9831,\n",
       "         6.8559,  9.5029,  8.7341,  8.6242,  6.4242,  9.2421, 10.6038,  6.2761,\n",
       "        10.6367,  6.4843,  8.9168,  7.6693,  7.8969,  6.0483,  7.9966,  9.3562,\n",
       "         5.5693,  9.3934,  6.1552,  8.2874,  6.5904,  7.1690,  5.6146,  6.7441,\n",
       "         8.1041,  4.8405,  8.1606,  5.8692,  7.5470,  5.5409,  6.4444,  5.1182,\n",
       "         5.4942,  6.7311,  4.0966,  7.0207,  5.6070,  6.6686,  4.4892,  5.7129,\n",
       "         4.5791], dtype=torch.float64, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data = t_batch\n",
    "x_data = x_batch.squeeze(1)\n",
    "\n",
    "model_DGM(torch.cat((t_data.unsqueeze(1), x_data),dim=1)).squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
