{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b03135c-635e-4232-8f7f-69939b7afce7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1.1\n",
    "## This *.ipynb file contains:\n",
    "\n",
    "- `LQRsolver`: a class required to be written, which can be __initialised__ with default time horizon T = 1 (which can also take value from users' input) and with the matrices specifying the LQR problem which are:\n",
    "    - `H` (`torch.Size([n,n]) torch.tensor`): the linear relations of dynamics between the total `n` state processes.\n",
    "    - `M` (`torch.Size([n,m]) torch.tensor`): the influences from `m` control variables to `n` state processes. \n",
    "    - `sigma`(`torch.Size([n,d]) torch.tensor`): the diffusion matrix from `d` Wiener processes to `n` state processes.\n",
    "    - `C` (`torch.Size([n,n]) torch.tensor`): the contribution matrix from state processes to runnning reward.\n",
    "    - `D` (`torch.Size([m,m]) torch.tensor`): the contribution matrix from the final value of state processes to runnning reward.\n",
    "    - `R` (`torch.Size([n,n]) torch.tensor`): the contribution matrix from the final values of state processes to terminal reward.\n",
    "    - `method` (`string`): the indicator for using euler scheme or 4th order Runge-Kutta4th order Runge-Kutta scheme.\n",
    "    \n",
    "    __Declaration for dimensions of matrices__:\n",
    "    Here `n` should be compatible with the dimension of state variable space and m is the dimension of control variable space.\n",
    "    Note that `n = m = 2` and `d = 1` in this exercise but can be extended to a higher dimension.\n",
    "\n",
    "    There are __3 main methods__ built in `LQRsolver` including\n",
    "\n",
    "    - `solve_riccati_ode`: __a numerical solver for Ricatti ODE__ which requires\n",
    "    \n",
    "        __input__ of\n",
    "    \n",
    "        - `time_grids`  `torch.Size([batch_size,l]) torch.Tensor`\n",
    "        \n",
    "        and __returns__\n",
    "        \n",
    "        - the values of solution function $S(t)$  `torch.Size([batch_size,l,n,n]) torch.tensor`\n",
    "        \n",
    "        (Two numerical methods are tried to be provided as options: Euler scheme and 4th order Runge-Kutta scheme)\n",
    "    \n",
    "    - `value_function`: __a computation of value function__ which requires\n",
    "\n",
    "        __inputs__ (in sequence) of \n",
    "        \n",
    "        - `t_batch`  `torch.Size([batch_size]) torch.tensor` whose entries took value initially from [0,1] but would be scaled by the given T in the further calculation\n",
    "        - `x_batch`  `torch.Size([batch_size,1,n]) torch.tensor`\n",
    "        \n",
    "        - `sol_method` `string` the indicator for using interpolation or using direct calculation for each t in t_batch (default setting is using interpolation)\n",
    "        \n",
    "        and __returns__\n",
    "        \n",
    "        - values of value_function `torch.Size([batch_size]) torch.tensor`\n",
    "        \n",
    "        \n",
    "    - `markov_control`: __a computation of Markov control function__ which requires\n",
    "\n",
    "        __inputs__ (in sequence) of \n",
    "        \n",
    "        - `t_batch`  `torch.Size([batch_size]) torch.tensor` whose entries took value initially from [0,1] but would be scaled by the given T in the further calculation\n",
    "        - `x_batch`  `torch.Size([batch_size,1,n]) torch.tensor`\n",
    "        \n",
    "        - `sol_method` `string` the indicator for using interpolation or using direct calculation for each t in t_batch (default setting is using interpolation)\n",
    "        \n",
    "        and __returns__\n",
    "        \n",
    "        - values of Markov_control_function  `torch.Size([batch_size,n]) torch.tensor`\n",
    "        \n",
    "        \n",
    "        \n",
    "- __A runnable sample__ including: \n",
    "\n",
    "    - a whole set of matrices for __initialisation__\n",
    "    - an example of __calculation of value function__ with given t_batch and x_batch\n",
    "    - an example of __calculation of Markov control function__ with given t_batch and x_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "162558f0-cfdf-43af-b560-b59a0191ed63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.integrate import quad\n",
    "import warnings #for alarming some inappropriate inputs\n",
    "\n",
    "class LQRSolver:\n",
    "    #default numerical method is Euler.\n",
    "    #Euler and Runge-Kutta are supported in this code.\n",
    "    def __init__(self, H, M, sigma, C, D, R, T = 1, method=\"euler\"):\n",
    "        \n",
    "        if not self.is_semi_positive_definite(C):\n",
    "            raise ValueError(\"Matrix C must be semi-positive definite.\")\n",
    "        if not self.is_semi_positive_definite(R):\n",
    "            raise ValueError(\"Matrix R must be semi-positive definite.\")\n",
    "        if not self.is_positive_definite(D):\n",
    "            raise ValueError(\"Matrix D must be positive definite.\")\n",
    " \n",
    "        self.H = H\n",
    "        self.M = M\n",
    "        self.sigma = sigma\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "        self.R = R\n",
    "        self.T = T\n",
    "        self.method = method \n",
    "    \n",
    "    def is_positive_definite(self, matrix):\n",
    "        \n",
    "        eigvals, _ = torch.linalg.eig(matrix)\n",
    "        real_parts = eigvals.real\n",
    "        return torch.all(real_parts > 0) \n",
    "\n",
    "    def is_semi_positive_definite(self, matrix):\n",
    "\n",
    "        eigvals, _ = torch.linalg.eig(matrix)\n",
    "        real_parts = eigvals.real\n",
    "        return torch.all(real_parts >= 0) \n",
    "\n",
    "    def solve_riccati_ode(self, time_grids):\n",
    "        \n",
    "        if not isinstance(time_grids, torch.Tensor):\n",
    "            raise TypeError(\"time_grid should be an batch_size*1-D torch.Tensor\")\n",
    "        else:\n",
    "            if not (torch.all(np.abs(time_grids[:,-1] - self.T) <= 1e-12) or torch.all(time_grids[:,0]>=0)):\n",
    "                print()\n",
    "                raise Exception(\"Please ensure that the first entry of time_grid >= 0 and the last entry is equal to T.\")\n",
    "            else:\n",
    "                time_grids_in = time_grids\n",
    "\n",
    "        time_grids_in = torch.flip(time_grids, dims=[1])\n",
    "        S = self.R.clone()\n",
    "        repl = torch.ones(time_grids_in.shape)\n",
    "        rep_exd = repl.unsqueeze(-1).unsqueeze(-1)\n",
    "        S_exd = S.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        S_repl = rep_exd*S_exd\n",
    "        dt = time_grids_in[:,1:]-time_grids_in[:,:-1]\n",
    "\n",
    "        for i in range(dt.shape[1]):\n",
    "            \n",
    "\n",
    "            if self.method == \"euler\":\n",
    "                S_repl[:,i+1] = self.euler_step(S_repl[:,i], dt[:,i])\n",
    "            elif self.method == \"rk4\":\n",
    "                S_repl[:,i+1] = self.rk4_step(S_repl[:,i], dt[:,i])\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported method\")\n",
    "\n",
    "        return torch.flip(S_repl, dims=[1])\n",
    "\n",
    "    def euler_step(self, S_in, dt_in):\n",
    "        \n",
    "        dS_in = -2 * self.H.T @ S_in + S_in @ self.M @ torch.inverse(self.D) @ self.M.T @ S_in - self.C\n",
    "\n",
    "        dt_resized = dt_in[:, None, None]\n",
    "\n",
    "        return S_in + dS_in * dt_resized\n",
    "    \n",
    "    def rk4_step(self, S_in, dt_in):\n",
    "\n",
    "        def riccati_derivative(S):\n",
    "            return -2 * self.H.T @ S_in + S_in @ self.M @ torch.inverse(self.D) @ self.M.T @ S_in - self.C\n",
    "        \n",
    "        dt_resized = dt_in[:, None, None]\n",
    "\n",
    "        k1 = riccati_derivative(S_in)\n",
    "        k2 = riccati_derivative(S_in + 0.5 *  k1 * dt_resized)\n",
    "        k3 = riccati_derivative(S_in + 0.5 *  k2 * dt_resized)\n",
    "        k4 = riccati_derivative(S_in + k3 * dt_resized)\n",
    "\n",
    "        return S_in + (k1 + 2*k2 + 2*k3 + k4)*dt_resized/6\n",
    "\n",
    "    def value_function(self, t_batch, x_batch, sol_method = 'interpolation'):\n",
    "        \n",
    "        if sol_method == 'interpolation':\n",
    "            \n",
    "            N_step = 5000\n",
    "            \n",
    "            if not (t_batch.dim() == 1 and torch.all((t_batch >= 0) & (t_batch <= 1))):\n",
    "                raise TypeError(\"t_batch should be a 1D tensor in which every entry is in [0,1].\")\n",
    "            else:\n",
    "                if not (x_batch.dim() == 3 and x_batch.size()[0] == len(t_batch) and x_batch.size()[1] == 1 and x_batch.size()[2] == self.H.size()[0]):\n",
    "                    raise TypeError(\"x_batch should have shape (%d, 1, %d).\"%(len(t_batch),self.H.size(2)))\n",
    "            \n",
    "            time_grid = torch.stack([torch.linspace(0, self.T, N_step, dtype=torch.double) for i in [0]])\n",
    "            \n",
    "            S_tensor_tensor = self.solve_riccati_ode(time_grid)\n",
    "            \n",
    "            index_s_1 = torch.searchsorted(time_grid[0,:], torch.min(t_batch), right=True) - 1\n",
    "            time_grid_for_intpl = time_grid[0,index_s_1:]\n",
    "            S_tensor_tensor_for_intpl = S_tensor_tensor[0,index_s_1:]\n",
    "            \n",
    "            time_grid_for_intpl_np = time_grid_for_intpl.numpy()\n",
    "            S_tensor_tensor_for_intpl_np = S_tensor_tensor_for_intpl.numpy()\n",
    "            t_batch_np = t_batch.numpy()\n",
    "            \n",
    "            S_c_spl = CubicSpline(time_grid_for_intpl_np, S_tensor_tensor_for_intpl_np)\n",
    "            \n",
    "            traces = torch.einsum('bii->b', self.sigma @ self.sigma.transpose(1,2) @ S_tensor_tensor_for_intpl).unsqueeze(1).unsqueeze(2)\n",
    "            trace_cubic = CubicSpline(time_grid_for_intpl_np, traces.numpy())\n",
    "            \n",
    "            def S_intpl(t_batch_np_in):\n",
    "                return torch.from_numpy(S_c_spl(t_batch_np_in))\n",
    "                \n",
    "            S_t_s = S_intpl(t_batch_np)\n",
    "            x_batch_T = x_batch.transpose(1, 2) \n",
    "            \n",
    "            xTSx = x_batch @ S_t_s @ x_batch_T\n",
    "            \n",
    "            \n",
    "            for i in range(len(t_batch_np)):\n",
    "                intgl, error = quad(trace_cubic, t_batch_np[i], self.T)\n",
    "                xTSx[i,0]+= intgl\n",
    "            \n",
    "            v_tx = xTSx.squeeze()\n",
    "            \n",
    "            \n",
    "        if sol_method == 'direct_calcul':\n",
    "        \n",
    "            # Verify the shapes of the inputs.\n",
    "\n",
    "            if not (t_batch.dim() == 1 and torch.all((t_batch >= 0) & (t_batch <= 1))):\n",
    "                raise TypeError(\"t_batch should be a 1D tensor in which every entry is in [0,1].\")\n",
    "            else:\n",
    "                if not (x_batch.dim() == 3 and x_batch.size()[0] == len(t_batch) and x_batch.size()[1] == 1 and x_batch.size()[2] == self.H.size()[0]):\n",
    "                    raise TypeError(\"x_batch should have shape (%d, 1, %d).\"%(len(t_batch),self.H.size(2)))\n",
    "\n",
    "            time_grids = torch.stack([torch.linspace(float(t), self.T, 5000, dtype=torch.double) for t in t_batch])\n",
    "\n",
    "            S_tensor_tensor = self.solve_riccati_ode(time_grids)\n",
    "            #print(S_tensor_tensor.shape)\n",
    "            S_t_s = S_tensor_tensor[:, 0, :, :]\n",
    "            S_t_T = S_tensor_tensor[:, 1:, :, :]\n",
    "            x_batch_T = x_batch.transpose(1, 2) \n",
    "\n",
    "            xTSx = x_batch @ S_t_s @ x_batch_T\n",
    "\n",
    "            dts = time_grids[:, 1:] - time_grids[:, :-1]\n",
    "\n",
    "            sigma_T = self.sigma.transpose(1,2)\n",
    "\n",
    "            trace_for_int = torch.einsum('bcii->bc', self.sigma @ self.sigma.transpose(1, 2) @ S_t_T.transpose(0,1)).unsqueeze(1).unsqueeze(2)\n",
    "            trace_for_int = trace_for_int.squeeze() \n",
    "\n",
    "            integral_part = dts @ trace_for_int\n",
    "\n",
    "            v_tx = xTSx.squeeze() + torch.diag(integral_part).squeeze()\n",
    "        \n",
    "        return v_tx\n",
    "\n",
    "    def markov_control(self, t_batch, x_batch, sol_method = 'interpolation'):\n",
    "        \n",
    "        if sol_method == 'interpolation':\n",
    "            \n",
    "            N_step = 5000\n",
    "            \n",
    "            if not (t_batch.dim() == 1 and torch.all((t_batch >= 0) & (t_batch <= 1))):\n",
    "                raise TypeError(\"t_batch should be a 1D tensor in which every entry is in [0,1].\")\n",
    "            else:\n",
    "                if not (x_batch.dim() == 3 and x_batch.size()[0] == len(t_batch) and x_batch.size()[1] == 1 and x_batch.size()[2] == self.H.size()[0]):\n",
    "                    raise TypeError(\"x_batch should have shape (%d, 1, %d).\"%(len(t_batch),self.H.size(2)))\n",
    "            \n",
    "            time_grid = torch.stack([torch.linspace(0, self.T, N_step, dtype=torch.double) for i in [0]])\n",
    "            \n",
    "            S_tensor_tensor = self.solve_riccati_ode(time_grid)\n",
    "            \n",
    "            index_s_1 = torch.searchsorted(time_grid[0,:], torch.min(t_batch), right=True) - 1\n",
    "            time_grid_for_intpl = time_grid[0,index_s_1:]\n",
    "            S_tensor_tensor_for_intpl = S_tensor_tensor[0,index_s_1:]\n",
    "            \n",
    "            time_grid_for_intpl_np = time_grid_for_intpl.numpy()\n",
    "            S_tensor_tensor_for_intpl_np = S_tensor_tensor_for_intpl.numpy()\n",
    "            t_batch_np = t_batch.numpy()\n",
    "            \n",
    "            S_c_spl = CubicSpline(time_grid_for_intpl_np, S_tensor_tensor_for_intpl_np)\n",
    "            \n",
    "            def S_intpl(t_batch_np_in):\n",
    "                return torch.from_numpy(S_c_spl(t_batch_np_in))\n",
    "                \n",
    "            S_t_s = S_intpl(t_batch_np)\n",
    "            x_batch_T = x_batch.transpose(1, 2) \n",
    "            \n",
    "            MT = self.M.T\n",
    "            D_inv = torch.inverse(self.D)\n",
    "            x = torch.transpose(x_batch,dim0 = 2,dim1 = 1)\n",
    "            a_tx = - D_inv @ MT @ S_t_s @ x_batch_T\n",
    "            a_tx = torch.transpose(a_tx,dim0 = 1,dim1 = 2).squeeze()    \n",
    "            \n",
    "        if sol_method == 'direct_calcul':\n",
    "        \n",
    "            # Verify the shapes of the inputs.\n",
    "\n",
    "            if not (t_batch.dim() == 1 and torch.all((t_batch >= 0) & (t_batch <= 1))):\n",
    "                raise TypeError(\"t_batch should be a 1D tensor in which every entry is in [0,1].\")\n",
    "            else:\n",
    "                if not (x_batch.dim() == 3 and x_batch.size()[0] == len(t_batch) and x_batch.size()[1] == 1 and x_batch.size()[2] == self.H.size()[0]):\n",
    "                    raise TypeError(\"x_batch should have shape (%d, 1, %d).\"%(len(t_batch),self.H.size(2)))\n",
    "\n",
    "            time_grids = torch.stack([torch.linspace(float(t), self.T, 5000, dtype=torch.double) for t in t_batch])\n",
    "\n",
    "            S_tensor_tensor = self.solve_riccati_ode(time_grids)\n",
    "\n",
    "            #print(S_tensor_tensor.shape)\n",
    "\n",
    "            S_t_s = S_tensor_tensor[:, 0, :, :]\n",
    "            x_batch_T = x_batch.transpose(1, 2) \n",
    "\n",
    "            MT = self.M.T\n",
    "            D_inv = torch.inverse(self.D)\n",
    "            x = torch.transpose(x_batch,dim0 = 2,dim1 = 1)\n",
    "            a_tx = - D_inv @ MT @ S_t_s @ x_batch_T\n",
    "            a_tx = torch.transpose(a_tx,dim0 = 1,dim1 = 2).squeeze()\n",
    "\n",
    "        return a_tx.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4dd6c40d-6d1f-42b8-b3ea-b6a8b24777f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialization\n",
    "H = torch.tensor([[1.0, 2.0], [-2.0, -3.0]], dtype=torch.double)\n",
    "M = torch.tensor([[1.0,0.0], [0.0,1.0]], dtype=torch.double)\n",
    "sigma = torch.tensor([[[0.5249],[0.4072]]], dtype=torch.double) \n",
    "C = torch.tensor([[2.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive semi-definite\n",
    "D = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive definite\n",
    "R = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive semi-definite\n",
    "T = 5.0\n",
    "method = 'rk4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87921136-9297-41af-bd3c-e856dd885dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solver = LQRSolver(H, M, sigma, C, D, R, T, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a491721b-d25f-4ec7-803e-7dc9515d09b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_batch = torch.linspace(0.1,0.2,20)\n",
    "x_batch = torch.rand([t_batch.shape[0],1,2], dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aa36c889-44f8-472d-a80e-fe44bd40db1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_batch_M = torch.max(t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3c9b7d06-3064-476b-9209-6ef193919f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000298023224"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(torch.max(t_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cfea864c-699d-4c69-870e-62a12a961175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.8017, 3.2001, 2.6930, 2.8737, 3.6841, 2.5074, 2.2399, 3.5025, 2.9336,\n",
       "        2.2143, 2.3695, 2.3450, 2.7833, 3.2298, 2.2060, 3.2385, 3.7156, 3.0390,\n",
       "        3.0409, 2.9704], dtype=torch.float64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.value_function(t_batch, x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b5d6219d-7a0b-41d0-87e1-5f88caf4288f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.8017, 3.2001, 2.6930, 2.8736, 3.6841, 2.5074, 2.2399, 3.5025, 2.9336,\n",
       "        2.2143, 2.3695, 2.3450, 2.7832, 3.2298, 2.2060, 3.2385, 3.7156, 3.0390,\n",
       "        3.0408, 2.9704], dtype=torch.float64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.value_function(t_batch, x_batch,'direct_calcul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f8a5d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2149, -0.7407]],\n",
       "\n",
       "        [[-0.8261, -0.5508]],\n",
       "\n",
       "        [[-0.6191, -0.3911]],\n",
       "\n",
       "        [[-0.9509, -0.5182]],\n",
       "\n",
       "        [[-0.9813, -0.6693]],\n",
       "\n",
       "        [[-0.3239, -0.2695]],\n",
       "\n",
       "        [[ 0.0871, -0.0389]],\n",
       "\n",
       "        [[-1.1609, -0.6856]],\n",
       "\n",
       "        [[-1.0139, -0.5496]],\n",
       "\n",
       "        [[ 0.1367,  0.0096]],\n",
       "\n",
       "        [[-0.0243, -0.1626]],\n",
       "\n",
       "        [[-0.1051, -0.1624]],\n",
       "\n",
       "        [[-0.6759, -0.4336]],\n",
       "\n",
       "        [[-0.8300, -0.5625]],\n",
       "\n",
       "        [[ 0.0865,  0.0079]],\n",
       "\n",
       "        [[-1.0286, -0.6126]],\n",
       "\n",
       "        [[-1.0424, -0.6925]],\n",
       "\n",
       "        [[-1.0596, -0.5859]],\n",
       "\n",
       "        [[-0.7057, -0.5003]],\n",
       "\n",
       "        [[-0.9013, -0.5331]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.markov_control(t_batch, x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "002013f8-7e95-4e8f-899c-2cc3a22528b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2149, -0.7407]],\n",
       "\n",
       "        [[-0.8261, -0.5508]],\n",
       "\n",
       "        [[-0.6191, -0.3911]],\n",
       "\n",
       "        [[-0.9509, -0.5182]],\n",
       "\n",
       "        [[-0.9813, -0.6693]],\n",
       "\n",
       "        [[-0.3239, -0.2695]],\n",
       "\n",
       "        [[ 0.0871, -0.0389]],\n",
       "\n",
       "        [[-1.1609, -0.6856]],\n",
       "\n",
       "        [[-1.0139, -0.5496]],\n",
       "\n",
       "        [[ 0.1367,  0.0096]],\n",
       "\n",
       "        [[-0.0243, -0.1626]],\n",
       "\n",
       "        [[-0.1051, -0.1624]],\n",
       "\n",
       "        [[-0.6759, -0.4336]],\n",
       "\n",
       "        [[-0.8300, -0.5625]],\n",
       "\n",
       "        [[ 0.0865,  0.0079]],\n",
       "\n",
       "        [[-1.0286, -0.6126]],\n",
       "\n",
       "        [[-1.0424, -0.6925]],\n",
       "\n",
       "        [[-1.0596, -0.5859]],\n",
       "\n",
       "        [[-0.7057, -0.5003]],\n",
       "\n",
       "        [[-0.9013, -0.5331]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.markov_control(t_batch, x_batch,'direct_calcul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69cae9-0cd1-4809-b853-6c1826fb3fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
