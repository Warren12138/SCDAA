{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "2e688f0c-ce74-421a-ad5c-d20cd9a268bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "6ef790c7-e56b-400a-ad39-7db60b81ea6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H = torch.tensor([[1.0, 2.0], [-2.0, -3.0]], dtype=torch.double)\n",
    "M = torch.tensor([[1.0,0.0], [0.0,1.0]], dtype=torch.double)\n",
    "sig = torch.tensor([[[0.5249],[0.4072]]], dtype=torch.double) \n",
    "C = torch.tensor([[2.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive semi-definite\n",
    "D = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive definite\n",
    "R = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive semi-definite\n",
    "T = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "e4e5a62d-c85e-40c5-ab11-02fe915082ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_batch = torch.linspace(0.2,0.3,20)\n",
    "\n",
    "T = 1\n",
    "R = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.double)  # Positive semi-definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "62145a74-f583-44ac-bc25-65ab3da9bd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_batch = torch.ones([t_batch.shape[0],1,2], dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "b002dad4-6e6d-426e-8234-aa1ff4bcb9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ff526057-4684-4db8-aa39-f789f77f4398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "3bd7177f-3e6d-4a97-bca1-a9d70fda84c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_grids = time_grids_tensor = torch.stack([\n",
    "    torch.linspace(0, T, 6, dtype=torch.double) for i in [0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "a6ee337b-4923-4c03-a354-974c42c8acb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_grids[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "59b3ad56-e74b-4d60-b857-faecaca07a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "time_grids[:,0]>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "76136db1-1449-4b09-b287-4d08d9daeda5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.all(np.abs(time_grids[:,-1] - T) <= 1e-12) or torch.all(time_grids[:,0]>=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "ac480961-85b0-4a36-b290-e20ffc508615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_grids_in = torch.flip(time_grids, dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "97ebb88f-dc6a-4ade-8140-8a288eb89966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8000, 0.6000, 0.4000, 0.2000, 0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_grids_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "771eb699-ed71-4f11-9278-a01b93aad6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = R.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "04987966-4409-4c78-af7d-673532461f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repl = torch.ones(time_grids_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "c86f1507-e12f-4d10-a2a3-1d8b54531668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "3bf33c27-7a91-491a-92c8-443218c8bdd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "d07239e9-a69e-4206-8596-1ba7eff2f8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rep_exd = repl.unsqueeze(-1).unsqueeze(-1)  # 现在形状为 (a, b, 1, 1)\n",
    "\n",
    "# 将矩阵扩展到 (1, 1, m, n) 以便进行广播\n",
    "S_exd = S.unsqueeze(0).unsqueeze(0) \n",
    "\n",
    "S_repl = rep_exd*S_exd\n",
    "dt = time_grids_in[:,1:]-time_grids_in[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "8b54b5ef-73fa-4f15-b0c2-46c653c8e7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S_repl = torch.flip(S_repl, dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "154cb40e-f704-447d-a4b3-d5a4d6cf62a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "493c897f-f550-4a22-87c3-421cfe7e0977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euler_step(S_in, dt_in):\n",
    "    \n",
    "    dS_in = -2 * H.T @ S_in + S_in @ M @ torch.inverse(D) @ M.T @ S_in - C\n",
    "\n",
    "    dt_resized = dt_in[:, None, None]\n",
    "\n",
    "    return S_in + dS_in * dt_resized\n",
    "\n",
    "def rk4_step(S_in, dt_in):\n",
    "    def riccati_derivative(S):\n",
    "        return -2 * H.T @ S_in + S_in @ M @ torch.inverse(D) @ M.T @ S_in - C\n",
    "    dt_resized = dt_in[:, None, None]\n",
    "    k1 = riccati_derivative(S_in)\n",
    "    k2 = riccati_derivative(S_in + 0.5 *  k1 * dt_resized)\n",
    "    k3 = riccati_derivative(S_in + 0.5 *  k2 * dt_resized)\n",
    "    k4 = riccati_derivative(S_in + k3 * dt_resized)\n",
    "\n",
    "    return S_in + (k1 + 2*k2 + 2*k3 + k4)*dt_resized/6\n",
    "\n",
    "for i in range(dt.shape[1]):\n",
    "    \n",
    "    S_repl[:,i+1] = euler_step(S_repl[:,i], dt[:,i])\n",
    "\n",
    "    \n",
    "    #S_repl[:,i+1] = rk4_step(S_repl[:,i], dt[:,i])\n",
    "\n",
    "\n",
    "S_repl = torch.flip(S_repl, dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4c143257-11ee-412b-8978-38c4f0f3fb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_s_1 = torch.searchsorted(time_grids[0,:], torch.min(t_batch), right=True) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "4f416985-c473-4f69-9595-4ddadbc303fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.4000, 0.6000, 0.8000, 1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_grids[0,index_s_1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "344ce401-16dc-4fdb-9726-c2f52325def8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_grid_for_intpl = time_grids[0,index_s_1:]\n",
    "S_repl_for_intpl = S_repl[0,index_s_1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "84e4dd73-a328-4b25-a9a5-263cfa065871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_grid_for_intpl.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "239da67e-27b8-4da0-ad74-fde3c4d1b291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_s_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "e9a1eb8b-55e5-48fb-8212-36b2d98b5dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5008, -0.5171],\n",
       "         [ 0.8353, -0.1473]],\n",
       "\n",
       "        [[ 1.5552, -0.6097],\n",
       "         [ 0.8742, -0.2166]],\n",
       "\n",
       "        [[ 1.6160, -0.7360],\n",
       "         [ 0.8960, -0.2800]],\n",
       "\n",
       "        [[ 1.6000, -0.8000],\n",
       "         [ 0.8000, -0.2000]],\n",
       "\n",
       "        [[ 1.0000,  0.0000],\n",
       "         [ 0.0000,  1.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_repl_for_intpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "7fce1929-56a1-4ff8-aaec-4e1d3aacb6d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traces = torch.einsum('bii->b', sig @ sig.transpose(1,2) @ S_repl_for_intpl).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "9b5d8b15-992f-43e3-8c36-9a7e667aa728",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-6:\n",
      "Process SpawnProcess-11:\n",
      "Process SpawnProcess-12:\n",
      "Process SpawnProcess-8:\n",
      "Process SpawnProcess-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-7:\n",
      "Process SpawnProcess-4:\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ysrae1/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'int_fun' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[567], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 使用ProcessPoolExecutor并行计算积分\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m----> 3\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(int_fun, t_batch_np))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/process.py:606\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    607\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "2fb6bc46-1f69-4324-a5a6-27fe1f5eec6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_cubic = CubicSpline(time_grid_np, traces.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "e6804361-a618-433f-b671-d05dfd5b6950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def int_fun(t):\n",
    "    \n",
    "    return trace_cubic(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "ae54cccb-ab46-447e-8fbf-22c13a84ec80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._cubic.CubicSpline at 0x31846a3f0>"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "ab363679-c2b6-4435-821a-ddbfeb599807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, error = quad(int_fun, 0.2, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "b142cb44-3582-4442-bf29-12afaef1b0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2       , 0.20526317, 0.21052632, 0.21578948, 0.22105263,\n",
       "       0.2263158 , 0.23157896, 0.23684211, 0.24210528, 0.24736843,\n",
       "       0.25263157, 0.25789475, 0.2631579 , 0.26842105, 0.27368423,\n",
       "       0.27894738, 0.28421053, 0.28947368, 0.29473686, 0.3       ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "8e935f95-a572-4623-bfba-d8c23f346776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(t_batch_np)):\n",
    "    intgl, error = quad(int_fun, t_batch_np[i], T)\n",
    "    xTSx[i,0]+= intgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "ab951429-3b6c-47d8-83d7-7d48376fecf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6695], dtype=torch.float64)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTSx[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b545d08-417a-4556-9628-5e37172f437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_repl_for_intpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "4a9f8158-c492-4afa-8c8e-48642ed641ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "# 将PyTorch张量转换为NumPy数组\n",
    "time_grid_np = time_grid_for_intpl.numpy()\n",
    "S_repl_for_intpl_np = S_repl_for_intpl.numpy()\n",
    "t_batch_np = t_batch.numpy()\n",
    "\n",
    "\n",
    "\n",
    "# 创建三次样条插值函数\n",
    "cubic_spline = CubicSpline(time_grid_np, S_repl_for_intpl_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "90c1dd91-44d2-4f2e-ad93-75e96e5671b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def S_intpl(t_batch_np_in):\n",
    "    return torch.from_numpy(cubic_spline(t_batch_np_in))\n",
    "\n",
    "S_t_s = S_intpl(t_batch_np)\n",
    "x_batch_T = x_batch.transpose(1,2)\n",
    "xTSx = x_batch @ S_t_s @ x_batch_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "1a4da29e-14bb-4e6d-aca0-843c6ca15afa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6717], dtype=torch.float64)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTSx[0,0]+= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "00f6db63-f136-40ff-9f3d-9b41674fd12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def traces(t_batch_np_in):\n",
    "    S_t_hat = S_intpl(t_batch_np_in)\n",
    "    return torch.einsum('bii->b', sig @ sig.transpose(1,2) @ S_t_hat.transpose(1,2)).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c23e6-f857-4612-915d-7c1f5d1d5b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "8bd1ce60-04bb-4292-a92f-c7f8101de246",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4571]],\n",
       "\n",
       "        [[0.4568]],\n",
       "\n",
       "        [[0.4566]],\n",
       "\n",
       "        [[0.4563]],\n",
       "\n",
       "        [[0.4561]],\n",
       "\n",
       "        [[0.4558]],\n",
       "\n",
       "        [[0.4556]],\n",
       "\n",
       "        [[0.4554]],\n",
       "\n",
       "        [[0.4552]],\n",
       "\n",
       "        [[0.4549]],\n",
       "\n",
       "        [[0.4547]],\n",
       "\n",
       "        [[0.4545]],\n",
       "\n",
       "        [[0.4543]],\n",
       "\n",
       "        [[0.4541]],\n",
       "\n",
       "        [[0.4539]],\n",
       "\n",
       "        [[0.4537]],\n",
       "\n",
       "        [[0.4535]],\n",
       "\n",
       "        [[0.4533]],\n",
       "\n",
       "        [[0.4531]],\n",
       "\n",
       "        [[0.4529]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces(t_batch_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de7f28-d941-4089-b907-b9d995354401",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = torch.einsum('bcii->bc', sig @ sig.transpose(1,2) @ S_t_T.transpose(0,1)).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "425f361b-aa58-4181-82d3-f3909a91603e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'quad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[524], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m integral_value, error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquad(traces, t_batch_np, T)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'quad'"
     ]
    }
   ],
   "source": [
    "integral_value, error = torch.quad(traces, t_batch_np, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e77a37c1-1c51-47ed-8cef-e478e595b9c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6717]],\n",
       "\n",
       "        [[1.6695]],\n",
       "\n",
       "        [[1.6673]],\n",
       "\n",
       "        [[1.6651]],\n",
       "\n",
       "        [[1.6630]],\n",
       "\n",
       "        [[1.6610]],\n",
       "\n",
       "        [[1.6590]],\n",
       "\n",
       "        [[1.6570]],\n",
       "\n",
       "        [[1.6550]],\n",
       "\n",
       "        [[1.6531]],\n",
       "\n",
       "        [[1.6512]],\n",
       "\n",
       "        [[1.6494]],\n",
       "\n",
       "        [[1.6475]],\n",
       "\n",
       "        [[1.6457]],\n",
       "\n",
       "        [[1.6440]],\n",
       "\n",
       "        [[1.6422]],\n",
       "\n",
       "        [[1.6405]],\n",
       "\n",
       "        [[1.6387]],\n",
       "\n",
       "        [[1.6370]],\n",
       "\n",
       "        [[1.6353]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "e0f3bbec-e403-4254-a165-b5f0fd59e4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "a01216f1-a503-4fd0-8d20-619d846b9bb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.50080527, -0.51712491],\n",
       "        [ 0.83528246, -0.14725131]],\n",
       "\n",
       "       [[ 1.50234677, -0.51981014],\n",
       "        [ 0.8366994 , -0.14976123]],\n",
       "\n",
       "       [[ 1.50387733, -0.52246434],\n",
       "        [ 0.83809057, -0.15221829]],\n",
       "\n",
       "       [[ 1.50539738, -0.525089  ],\n",
       "        [ 0.83945636, -0.15462383]],\n",
       "\n",
       "       [[ 1.50690732, -0.52768556],\n",
       "        [ 0.84079713, -0.15697914]],\n",
       "\n",
       "       [[ 1.50840757, -0.53025552],\n",
       "        [ 0.84211327, -0.15928557]],\n",
       "\n",
       "       [[ 1.50989856, -0.53280032],\n",
       "        [ 0.84340515, -0.16154442]],\n",
       "\n",
       "       [[ 1.51138068, -0.53532144],\n",
       "        [ 0.84467315, -0.16375699]],\n",
       "\n",
       "       [[ 1.51285437, -0.53782036],\n",
       "        [ 0.84591764, -0.16592463]],\n",
       "\n",
       "       [[ 1.51432002, -0.54029852],\n",
       "        [ 0.847139  , -0.16804863]],\n",
       "\n",
       "       [[ 1.51577807, -0.54275741],\n",
       "        [ 0.84833761, -0.17013033]],\n",
       "\n",
       "       [[ 1.51722893, -0.54519851],\n",
       "        [ 0.84951384, -0.17217104]],\n",
       "\n",
       "       [[ 1.518673  , -0.54762325],\n",
       "        [ 0.85066807, -0.17417207]],\n",
       "\n",
       "       [[ 1.5201107 , -0.55003311],\n",
       "        [ 0.85180068, -0.17613474]],\n",
       "\n",
       "       [[ 1.52154247, -0.55242959],\n",
       "        [ 0.85291204, -0.17806038]],\n",
       "\n",
       "       [[ 1.52296869, -0.55481412],\n",
       "        [ 0.85400252, -0.17995028]],\n",
       "\n",
       "       [[ 1.5243898 , -0.55718819],\n",
       "        [ 0.85507251, -0.18180578]],\n",
       "\n",
       "       [[ 1.5258062 , -0.55955325],\n",
       "        [ 0.85612239, -0.18362819]],\n",
       "\n",
       "       [[ 1.52721832, -0.56191079],\n",
       "        [ 0.85715252, -0.18541885]],\n",
       "\n",
       "       [[ 1.52862657, -0.56426226],\n",
       "        [ 0.85816328, -0.18717904]]])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubic_spline(t_batch_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "c17387d5-f272-425f-a7ce-e0e5faebd621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5008, -0.5171],\n",
       "        [ 0.8353, -0.1473]], dtype=torch.float64)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(cubic_spline(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "8958e6e8-2911-4bf1-837d-e0d85996f017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5552, -0.6097],\n",
       "         [ 0.8742, -0.2166]],\n",
       "\n",
       "        [[ 1.6160, -0.7360],\n",
       "         [ 0.8960, -0.2800]],\n",
       "\n",
       "        [[ 1.6000, -0.8000],\n",
       "         [ 0.8000, -0.2000]],\n",
       "\n",
       "        [[ 1.0000,  0.0000],\n",
       "         [ 0.0000,  1.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_repl[0,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "2691ed11-6cee-4b63-a32f-287c86c927bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_trans = x_batch.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "734a44a8-14f9-4c99-b29a-7cc18655f04e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]],\n",
       "\n",
       "        [[2.]]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch@x_batch.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "287e9f12-d708-49ce-9385-bedfdf107fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S_t_s = S_repl[:,0,:,:]\n",
    "S_t_T = S_repl[:,1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2e04c-5bc7-41da-9c33-9d6ce6557ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_t_s = S_repl[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a18c7aa3-856b-49d8-bb85-9670f27cc481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4688, -0.4662],\n",
       "         [ 0.8075, -0.1022]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "cf5e1a81-08c4-483a-af5b-bd6a811f15dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "torch.Size([5, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(sig.shape)\n",
    "print(sig.transpose(1,2).shape)\n",
    "print(S_t_T.transpose(0,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "8b089758-2fd8-4325-8218-d9f7601c0224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5249],\n",
       "         [0.4072]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45bbc299-a669-4511-b269-bd19ed0048b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]],\n",
       "\n",
       "        [[1.7079]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch @ S_t_s @ x_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bebd2e39-2c8f-4756-a9f1-d1bf725ef915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]],\n",
       "\n",
       "        [[ 2.2763, -0.5684],\n",
       "         [ 2.2763, -0.5684]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trans  @  x_batch @ S_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2141,
   "id": "f9f10218-7ee7-4886-bc40-66e90b677dda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.3787e+00,  1.9878e+00],\n",
       "          [-2.3787e+00,  1.9878e+00]],\n",
       "\n",
       "         [[-2.3603e+00,  1.9828e+00],\n",
       "          [-2.3603e+00,  1.9828e+00]],\n",
       "\n",
       "         [[-2.3420e+00,  1.9778e+00],\n",
       "          [-2.3420e+00,  1.9778e+00]],\n",
       "\n",
       "         [[-2.3236e+00,  1.9728e+00],\n",
       "          [-2.3236e+00,  1.9728e+00]],\n",
       "\n",
       "         [[-2.3053e+00,  1.9677e+00],\n",
       "          [-2.3053e+00,  1.9677e+00]],\n",
       "\n",
       "         [[-2.2870e+00,  1.9627e+00],\n",
       "          [-2.2870e+00,  1.9627e+00]],\n",
       "\n",
       "         [[-2.2687e+00,  1.9577e+00],\n",
       "          [-2.2687e+00,  1.9577e+00]],\n",
       "\n",
       "         [[-2.2504e+00,  1.9527e+00],\n",
       "          [-2.2504e+00,  1.9527e+00]],\n",
       "\n",
       "         [[-2.2321e+00,  1.9477e+00],\n",
       "          [-2.2321e+00,  1.9477e+00]],\n",
       "\n",
       "         [[-2.2139e+00,  1.9427e+00],\n",
       "          [-2.2139e+00,  1.9427e+00]],\n",
       "\n",
       "         [[-2.1956e+00,  1.9377e+00],\n",
       "          [-2.1956e+00,  1.9377e+00]],\n",
       "\n",
       "         [[-2.1774e+00,  1.9327e+00],\n",
       "          [-2.1774e+00,  1.9327e+00]],\n",
       "\n",
       "         [[-2.1592e+00,  1.9277e+00],\n",
       "          [-2.1592e+00,  1.9277e+00]],\n",
       "\n",
       "         [[-2.1410e+00,  1.9227e+00],\n",
       "          [-2.1410e+00,  1.9227e+00]],\n",
       "\n",
       "         [[-2.1229e+00,  1.9177e+00],\n",
       "          [-2.1229e+00,  1.9177e+00]],\n",
       "\n",
       "         [[-2.1047e+00,  1.9127e+00],\n",
       "          [-2.1047e+00,  1.9127e+00]],\n",
       "\n",
       "         [[-2.0866e+00,  1.9077e+00],\n",
       "          [-2.0866e+00,  1.9077e+00]],\n",
       "\n",
       "         [[-2.0684e+00,  1.9027e+00],\n",
       "          [-2.0684e+00,  1.9027e+00]],\n",
       "\n",
       "         [[-2.0503e+00,  1.8977e+00],\n",
       "          [-2.0503e+00,  1.8977e+00]],\n",
       "\n",
       "         [[-2.0322e+00,  1.8927e+00],\n",
       "          [-2.0322e+00,  1.8927e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.6024e+00,  1.7753e+00],\n",
       "          [-1.6024e+00,  1.7753e+00]],\n",
       "\n",
       "         [[-1.5895e+00,  1.7717e+00],\n",
       "          [-1.5895e+00,  1.7717e+00]],\n",
       "\n",
       "         [[-1.5766e+00,  1.7680e+00],\n",
       "          [-1.5766e+00,  1.7680e+00]],\n",
       "\n",
       "         [[-1.5636e+00,  1.7644e+00],\n",
       "          [-1.5636e+00,  1.7644e+00]],\n",
       "\n",
       "         [[-1.5507e+00,  1.7607e+00],\n",
       "          [-1.5507e+00,  1.7607e+00]],\n",
       "\n",
       "         [[-1.5377e+00,  1.7570e+00],\n",
       "          [-1.5377e+00,  1.7570e+00]],\n",
       "\n",
       "         [[-1.5248e+00,  1.7534e+00],\n",
       "          [-1.5248e+00,  1.7534e+00]],\n",
       "\n",
       "         [[-1.5118e+00,  1.7497e+00],\n",
       "          [-1.5118e+00,  1.7497e+00]],\n",
       "\n",
       "         [[-1.4988e+00,  1.7460e+00],\n",
       "          [-1.4988e+00,  1.7460e+00]],\n",
       "\n",
       "         [[-1.4858e+00,  1.7424e+00],\n",
       "          [-1.4858e+00,  1.7424e+00]],\n",
       "\n",
       "         [[-1.4728e+00,  1.7387e+00],\n",
       "          [-1.4728e+00,  1.7387e+00]],\n",
       "\n",
       "         [[-1.4598e+00,  1.7350e+00],\n",
       "          [-1.4598e+00,  1.7350e+00]],\n",
       "\n",
       "         [[-1.4468e+00,  1.7313e+00],\n",
       "          [-1.4468e+00,  1.7313e+00]],\n",
       "\n",
       "         [[-1.4337e+00,  1.7276e+00],\n",
       "          [-1.4337e+00,  1.7276e+00]],\n",
       "\n",
       "         [[-1.4207e+00,  1.7239e+00],\n",
       "          [-1.4207e+00,  1.7239e+00]],\n",
       "\n",
       "         [[-1.4076e+00,  1.7202e+00],\n",
       "          [-1.4076e+00,  1.7202e+00]],\n",
       "\n",
       "         [[-1.3946e+00,  1.7165e+00],\n",
       "          [-1.3946e+00,  1.7165e+00]],\n",
       "\n",
       "         [[-1.3815e+00,  1.7128e+00],\n",
       "          [-1.3815e+00,  1.7128e+00]],\n",
       "\n",
       "         [[-1.3684e+00,  1.7090e+00],\n",
       "          [-1.3684e+00,  1.7090e+00]],\n",
       "\n",
       "         [[-1.3553e+00,  1.7053e+00],\n",
       "          [-1.3553e+00,  1.7053e+00]]],\n",
       "\n",
       "\n",
       "        [[[-8.8860e-01,  1.5741e+00],\n",
       "          [-8.8860e-01,  1.5741e+00]],\n",
       "\n",
       "         [[-8.7932e-01,  1.5714e+00],\n",
       "          [-8.7932e-01,  1.5714e+00]],\n",
       "\n",
       "         [[-8.7001e-01,  1.5686e+00],\n",
       "          [-8.7001e-01,  1.5686e+00]],\n",
       "\n",
       "         [[-8.6069e-01,  1.5659e+00],\n",
       "          [-8.6069e-01,  1.5659e+00]],\n",
       "\n",
       "         [[-8.5136e-01,  1.5632e+00],\n",
       "          [-8.5136e-01,  1.5632e+00]],\n",
       "\n",
       "         [[-8.4201e-01,  1.5604e+00],\n",
       "          [-8.4201e-01,  1.5604e+00]],\n",
       "\n",
       "         [[-8.3264e-01,  1.5577e+00],\n",
       "          [-8.3264e-01,  1.5577e+00]],\n",
       "\n",
       "         [[-8.2325e-01,  1.5549e+00],\n",
       "          [-8.2325e-01,  1.5549e+00]],\n",
       "\n",
       "         [[-8.1385e-01,  1.5522e+00],\n",
       "          [-8.1385e-01,  1.5522e+00]],\n",
       "\n",
       "         [[-8.0443e-01,  1.5494e+00],\n",
       "          [-8.0443e-01,  1.5494e+00]],\n",
       "\n",
       "         [[-7.9499e-01,  1.5466e+00],\n",
       "          [-7.9499e-01,  1.5466e+00]],\n",
       "\n",
       "         [[-7.8553e-01,  1.5439e+00],\n",
       "          [-7.8553e-01,  1.5439e+00]],\n",
       "\n",
       "         [[-7.7606e-01,  1.5411e+00],\n",
       "          [-7.7606e-01,  1.5411e+00]],\n",
       "\n",
       "         [[-7.6657e-01,  1.5383e+00],\n",
       "          [-7.6657e-01,  1.5383e+00]],\n",
       "\n",
       "         [[-7.5707e-01,  1.5355e+00],\n",
       "          [-7.5707e-01,  1.5355e+00]],\n",
       "\n",
       "         [[-7.4754e-01,  1.5327e+00],\n",
       "          [-7.4754e-01,  1.5327e+00]],\n",
       "\n",
       "         [[-7.3800e-01,  1.5299e+00],\n",
       "          [-7.3800e-01,  1.5299e+00]],\n",
       "\n",
       "         [[-7.2845e-01,  1.5270e+00],\n",
       "          [-7.2845e-01,  1.5270e+00]],\n",
       "\n",
       "         [[-7.1887e-01,  1.5242e+00],\n",
       "          [-7.1887e-01,  1.5242e+00]],\n",
       "\n",
       "         [[-7.0928e-01,  1.5214e+00],\n",
       "          [-7.0928e-01,  1.5214e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.2670e-01,  1.3518e+00],\n",
       "          [-1.2670e-01,  1.3518e+00]],\n",
       "\n",
       "         [[-1.2012e-01,  1.3498e+00],\n",
       "          [-1.2012e-01,  1.3498e+00]],\n",
       "\n",
       "         [[-1.1353e-01,  1.3477e+00],\n",
       "          [-1.1353e-01,  1.3477e+00]],\n",
       "\n",
       "         [[-1.0694e-01,  1.3457e+00],\n",
       "          [-1.0694e-01,  1.3457e+00]],\n",
       "\n",
       "         [[-1.0035e-01,  1.3436e+00],\n",
       "          [-1.0035e-01,  1.3436e+00]],\n",
       "\n",
       "         [[-9.3760e-02,  1.3415e+00],\n",
       "          [-9.3760e-02,  1.3415e+00]],\n",
       "\n",
       "         [[-8.7171e-02,  1.3395e+00],\n",
       "          [-8.7171e-02,  1.3395e+00]],\n",
       "\n",
       "         [[-8.0582e-02,  1.3374e+00],\n",
       "          [-8.0582e-02,  1.3374e+00]],\n",
       "\n",
       "         [[-7.3993e-02,  1.3354e+00],\n",
       "          [-7.3993e-02,  1.3354e+00]],\n",
       "\n",
       "         [[-6.7404e-02,  1.3333e+00],\n",
       "          [-6.7404e-02,  1.3333e+00]],\n",
       "\n",
       "         [[-6.0815e-02,  1.3313e+00],\n",
       "          [-6.0815e-02,  1.3313e+00]],\n",
       "\n",
       "         [[-5.4226e-02,  1.3292e+00],\n",
       "          [-5.4226e-02,  1.3292e+00]],\n",
       "\n",
       "         [[-4.7637e-02,  1.3271e+00],\n",
       "          [-4.7637e-02,  1.3271e+00]],\n",
       "\n",
       "         [[-4.1048e-02,  1.3251e+00],\n",
       "          [-4.1048e-02,  1.3251e+00]],\n",
       "\n",
       "         [[-3.4460e-02,  1.3230e+00],\n",
       "          [-3.4460e-02,  1.3230e+00]],\n",
       "\n",
       "         [[-2.7871e-02,  1.3210e+00],\n",
       "          [-2.7871e-02,  1.3210e+00]],\n",
       "\n",
       "         [[-2.1281e-02,  1.3189e+00],\n",
       "          [-2.1281e-02,  1.3189e+00]],\n",
       "\n",
       "         [[-1.4693e-02,  1.3169e+00],\n",
       "          [-1.4693e-02,  1.3169e+00]],\n",
       "\n",
       "         [[-8.1038e-03,  1.3148e+00],\n",
       "          [-8.1038e-03,  1.3148e+00]],\n",
       "\n",
       "         [[-1.5146e-03,  1.3127e+00],\n",
       "          [-1.5146e-03,  1.3127e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00,  1.0000e+00],\n",
       "          [ 1.0000e+00,  1.0000e+00]]]])"
      ]
     },
     "execution_count": 2141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trans @ x_batch @ S_t_T.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "id": "c114ed7d-520a-4683-a195-2925ea4111b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sig = torch.tensor([[[0.5249],[0.4072]]], dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "33bb88d9-5f36-44dc-8e41-7c60b108d018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traces \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbcii->bc\u001b[39m\u001b[38;5;124m'\u001b[39m, sig \u001b[38;5;241m@\u001b[39m sig\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m S_t_T\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "traces = torch.einsum('bcii->bc', sig @ sig.transpose(1,2) @ S_t_T.transpose(0,1)).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2147,
   "id": "8d5c3e3c-3296-4492-b51a-78f30d7971d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2800, 0.4600, 0.6400, 0.8200, 1.0000],\n",
       "        [0.1053, 0.2842, 0.4632, 0.6421, 0.8211, 1.0000],\n",
       "        [0.1105, 0.2884, 0.4663, 0.6442, 0.8221, 1.0000],\n",
       "        [0.1158, 0.2926, 0.4695, 0.6463, 0.8232, 1.0000],\n",
       "        [0.1211, 0.2968, 0.4726, 0.6484, 0.8242, 1.0000],\n",
       "        [0.1263, 0.3011, 0.4758, 0.6505, 0.8253, 1.0000],\n",
       "        [0.1316, 0.3053, 0.4789, 0.6526, 0.8263, 1.0000],\n",
       "        [0.1368, 0.3095, 0.4821, 0.6547, 0.8274, 1.0000],\n",
       "        [0.1421, 0.3137, 0.4853, 0.6568, 0.8284, 1.0000],\n",
       "        [0.1474, 0.3179, 0.4884, 0.6589, 0.8295, 1.0000],\n",
       "        [0.1526, 0.3221, 0.4916, 0.6611, 0.8305, 1.0000],\n",
       "        [0.1579, 0.3263, 0.4947, 0.6632, 0.8316, 1.0000],\n",
       "        [0.1632, 0.3305, 0.4979, 0.6653, 0.8326, 1.0000],\n",
       "        [0.1684, 0.3347, 0.5011, 0.6674, 0.8337, 1.0000],\n",
       "        [0.1737, 0.3389, 0.5042, 0.6695, 0.8347, 1.0000],\n",
       "        [0.1789, 0.3432, 0.5074, 0.6716, 0.8358, 1.0000],\n",
       "        [0.1842, 0.3474, 0.5105, 0.6737, 0.8368, 1.0000],\n",
       "        [0.1895, 0.3516, 0.5137, 0.6758, 0.8379, 1.0000],\n",
       "        [0.1947, 0.3558, 0.5168, 0.6779, 0.8389, 1.0000],\n",
       "        [0.2000, 0.3600, 0.5200, 0.6800, 0.8400, 1.0000]])"
      ]
     },
     "execution_count": 2147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2149,
   "id": "1d61306c-301c-4019-9988-3e30d5a978a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dts = time_grids[:,1:] - time_grids[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2151,
   "id": "1ca45708-2572-47dd-8965-6d7debe03877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 2151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2153,
   "id": "7e12dfa2-70d0-4921-88c2-4859a9e1612f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1800, 0.1800, 0.1800, 0.1800, 0.1800],\n",
       "        [0.1789, 0.1789, 0.1789, 0.1789, 0.1789],\n",
       "        [0.1779, 0.1779, 0.1779, 0.1779, 0.1779],\n",
       "        [0.1768, 0.1768, 0.1768, 0.1768, 0.1768],\n",
       "        [0.1758, 0.1758, 0.1758, 0.1758, 0.1758],\n",
       "        [0.1747, 0.1747, 0.1747, 0.1747, 0.1747],\n",
       "        [0.1737, 0.1737, 0.1737, 0.1737, 0.1737],\n",
       "        [0.1726, 0.1726, 0.1726, 0.1726, 0.1726],\n",
       "        [0.1716, 0.1716, 0.1716, 0.1716, 0.1716],\n",
       "        [0.1705, 0.1705, 0.1705, 0.1705, 0.1705],\n",
       "        [0.1695, 0.1695, 0.1695, 0.1695, 0.1695],\n",
       "        [0.1684, 0.1684, 0.1684, 0.1684, 0.1684],\n",
       "        [0.1674, 0.1674, 0.1674, 0.1674, 0.1674],\n",
       "        [0.1663, 0.1663, 0.1663, 0.1663, 0.1663],\n",
       "        [0.1653, 0.1653, 0.1653, 0.1653, 0.1653],\n",
       "        [0.1642, 0.1642, 0.1642, 0.1642, 0.1642],\n",
       "        [0.1632, 0.1632, 0.1632, 0.1632, 0.1632],\n",
       "        [0.1621, 0.1621, 0.1621, 0.1621, 0.1621],\n",
       "        [0.1611, 0.1611, 0.1611, 0.1611, 0.1611],\n",
       "        [0.1600, 0.1600, 0.1600, 0.1600, 0.1600]])"
      ]
     },
     "execution_count": 2153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2155,
   "id": "af6efca4-b305-43f3-ba3c-82c30e65ce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1760, -0.1729, -0.1697, -0.1666, -0.1634, -0.1603, -0.1572,\n",
       "           -0.1540, -0.1509, -0.1478, -0.1446, -0.1415, -0.1383, -0.1352,\n",
       "           -0.1321, -0.1289, -0.1258, -0.1227, -0.1195, -0.1164]]],\n",
       "\n",
       "\n",
       "        [[[-0.0434, -0.0411, -0.0389, -0.0366, -0.0343, -0.0320, -0.0297,\n",
       "           -0.0273, -0.0250, -0.0227, -0.0204, -0.0181, -0.0158, -0.0134,\n",
       "           -0.0111, -0.0088, -0.0064, -0.0041, -0.0018,  0.0006]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0827,  0.0845,  0.0862,  0.0879,  0.0897,  0.0914,  0.0931,\n",
       "            0.0949,  0.0966,  0.0984,  0.1001,  0.1019,  0.1037,  0.1054,\n",
       "            0.1072,  0.1090,  0.1108,  0.1126,  0.1143,  0.1161]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2240,  0.2253,  0.2266,  0.2278,  0.2291,  0.2304,  0.2316,\n",
       "            0.2329,  0.2342,  0.2355,  0.2367,  0.2380,  0.2393,  0.2405,\n",
       "            0.2418,  0.2431,  0.2444,  0.2456,  0.2469,  0.2482]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "            0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "            0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413]]]])"
      ]
     },
     "execution_count": 2155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2157,
   "id": "195bacfc-95f1-475b-a3dc-e0a963027fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1800, 0.1800, 0.1800, 0.1800, 0.1800],\n",
       "        [0.1789, 0.1789, 0.1789, 0.1789, 0.1789],\n",
       "        [0.1779, 0.1779, 0.1779, 0.1779, 0.1779],\n",
       "        [0.1768, 0.1768, 0.1768, 0.1768, 0.1768],\n",
       "        [0.1758, 0.1758, 0.1758, 0.1758, 0.1758],\n",
       "        [0.1747, 0.1747, 0.1747, 0.1747, 0.1747],\n",
       "        [0.1737, 0.1737, 0.1737, 0.1737, 0.1737],\n",
       "        [0.1726, 0.1726, 0.1726, 0.1726, 0.1726],\n",
       "        [0.1716, 0.1716, 0.1716, 0.1716, 0.1716],\n",
       "        [0.1705, 0.1705, 0.1705, 0.1705, 0.1705],\n",
       "        [0.1695, 0.1695, 0.1695, 0.1695, 0.1695],\n",
       "        [0.1684, 0.1684, 0.1684, 0.1684, 0.1684],\n",
       "        [0.1674, 0.1674, 0.1674, 0.1674, 0.1674],\n",
       "        [0.1663, 0.1663, 0.1663, 0.1663, 0.1663],\n",
       "        [0.1653, 0.1653, 0.1653, 0.1653, 0.1653],\n",
       "        [0.1642, 0.1642, 0.1642, 0.1642, 0.1642],\n",
       "        [0.1632, 0.1632, 0.1632, 0.1632, 0.1632],\n",
       "        [0.1621, 0.1621, 0.1621, 0.1621, 0.1621],\n",
       "        [0.1611, 0.1611, 0.1611, 0.1611, 0.1611],\n",
       "        [0.1600, 0.1600, 0.1600, 0.1600, 0.1600]])"
      ]
     },
     "execution_count": 2157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2159,
   "id": "b2ca7415-ad33-4f74-8210-02969a5b2432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1395, -0.1367, -0.1339, -0.1311, -0.1284, -0.1256, -0.1228, -0.1200,\n",
       "         -0.1173, -0.1145, -0.1117, -0.1089, -0.1061, -0.1033, -0.1005, -0.0977,\n",
       "         -0.0949, -0.0921, -0.0893, -0.0865],\n",
       "        [ 0.0121,  0.0141,  0.0161,  0.0181,  0.0201,  0.0221,  0.0241,  0.0261,\n",
       "          0.0281,  0.0301,  0.0321,  0.0342,  0.0362,  0.0383,  0.0403,  0.0424,\n",
       "          0.0444,  0.0465,  0.0485,  0.0506],\n",
       "        [ 0.1697,  0.1713,  0.1729,  0.1745,  0.1760,  0.1776,  0.1792,  0.1808,\n",
       "          0.1824,  0.1840,  0.1856,  0.1872,  0.1888,  0.1903,  0.1919,  0.1935,\n",
       "          0.1951,  0.1967,  0.1983,  0.1999],\n",
       "        [ 0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "          0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "          0.4413,  0.4413,  0.4413,  0.4413]])"
      ]
     },
     "execution_count": 2159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr_squeezed.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2161,
   "id": "9cc10d27-f409-4800-9d86-9159775de987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1760, -0.1729, -0.1697, -0.1666, -0.1634, -0.1603, -0.1572, -0.1540,\n",
       "         -0.1509, -0.1478, -0.1446, -0.1415, -0.1383, -0.1352, -0.1321, -0.1289,\n",
       "         -0.1258, -0.1227, -0.1195, -0.1164],\n",
       "        [-0.0434, -0.0411, -0.0389, -0.0366, -0.0343, -0.0320, -0.0297, -0.0273,\n",
       "         -0.0250, -0.0227, -0.0204, -0.0181, -0.0158, -0.0134, -0.0111, -0.0088,\n",
       "         -0.0064, -0.0041, -0.0018,  0.0006],\n",
       "        [ 0.0827,  0.0845,  0.0862,  0.0879,  0.0897,  0.0914,  0.0931,  0.0949,\n",
       "          0.0966,  0.0984,  0.1001,  0.1019,  0.1037,  0.1054,  0.1072,  0.1090,\n",
       "          0.1108,  0.1126,  0.1143,  0.1161],\n",
       "        [ 0.2240,  0.2253,  0.2266,  0.2278,  0.2291,  0.2304,  0.2316,  0.2329,\n",
       "          0.2342,  0.2355,  0.2367,  0.2380,  0.2393,  0.2405,  0.2418,  0.2431,\n",
       "          0.2444,  0.2456,  0.2469,  0.2482],\n",
       "        [ 0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "          0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,  0.4413,\n",
       "          0.4413,  0.4413,  0.4413,  0.4413]])"
      ]
     },
     "execution_count": 2161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces.squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2163,
   "id": "de8f21e4-deb4-4544-b30d-596c21a2ed6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "Tr_squeezed = traces.squeeze()  # 形状变为 [4]\n",
    "#dt_transposed = dts.t()  # 由于dt的原始形状为[1, 4]，这里使用t()进行转置以匹配形状[4, 1]\n",
    "Tr_squeezed #= (Tr_squeezed[:-1] + Tr_squeezed[1:]) / 2\n",
    "# 计算矩阵乘法\n",
    "v_tx =  dts@Tr_squeezed\n",
    "print(dts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2165,
   "id": "0f628d3b-e7a2-41ea-8ba9-ab3aa11ab524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0952, 0.0961, 0.0970, 0.0980, 0.0989, 0.0997, 0.1006, 0.1015, 0.1023,\n",
       "        0.1031, 0.1039, 0.1047, 0.1055, 0.1062, 0.1070, 0.1077, 0.1084, 0.1091,\n",
       "        0.1097, 0.1104])"
      ]
     },
     "execution_count": 2165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(v_tx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2167,
   "id": "1367f92c-1f2b-4be1-9248-64decd9875d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0388, -1.0200, -1.0013, -0.9826, -0.9640, -0.9453, -0.9268, -0.9082,\n",
       "        -0.8897, -0.8713, -0.8528, -0.8345, -0.8161, -0.7978, -0.7795, -0.7613,\n",
       "        -0.7431, -0.7249, -0.7068, -0.6887])"
      ]
     },
     "execution_count": 2167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_batch @ S_t_s @ x_trans).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2169,
   "id": "0d3848fd-000b-4286-b16e-84fd7ee3c07f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "v_tx = torch.diag(v_tx).squeeze() + (x_batch @ S_t_s @ x_trans).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2171,
   "id": "e3660a9a-272e-4bfb-83ec-64673ee5ce02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9436, -0.9239, -0.9042, -0.8846, -0.8651, -0.8456, -0.8262, -0.8068,\n",
       "        -0.7874, -0.7682, -0.7489, -0.7298, -0.7106, -0.6916, -0.6726, -0.6536,\n",
       "        -0.6347, -0.6159, -0.5971, -0.5784])"
      ]
     },
     "execution_count": 2171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "424fa9fc-2c36-4831-8a9a-82fdf0c062fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[1., 0.],\n",
       "          [0., 1.]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48f8bc-6057-45c6-96f9-9c08b2dd0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "987fa2a1-8322-4776-9f42-e702fb5ed039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H = torch.tensor([[1.0, 2.0], [-2.0, -3.0]], dtype=torch.float32)\n",
    "M = torch.tensor([[1.0,0.0], [0.0,1.0]], dtype=torch.float32)\n",
    "sigma = torch.tensor([[0.5], [0.5]], dtype=torch.float32)  \n",
    "C = torch.tensor([[2.0, 0.0], [0.0, 1.0]], dtype=torch.float32)  # Positive semi-definite\n",
    "D = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.float32)  # Positive definite\n",
    "R = torch.tensor([[1.0, 0.0], [0.0, 1.0]], dtype=torch.float32)  # Positive semi-definite\n",
    "T = 5.0\n",
    "\n",
    "def euler_step(S, dt):\n",
    "    \n",
    "    dS = -2 * H.T @ S + S @ M @ torch.inverse(D) @ M.T @ S - C\n",
    "\n",
    "    dt_resized = dt[:, None, None]\n",
    "\n",
    "    S_next = S + dS * dt_resized\n",
    "\n",
    "    return S_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494acd76-20b4-4dc9-b7b5-918985af53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_riccati_ode(self, time_grid):\n",
    "\n",
    "    if not isinstance(time_grid, torch.Tensor):\n",
    "        raise TypeError(\"time_grid should be an batch_size*1 torch.Tensor\")\n",
    "    else:\n",
    "        if not ((np.abs(time_grid[-1] - self.T) <= 1e-12) or (time_grid[0]>=0)):\n",
    "            raise Exception(\"Please ensure that the first entry of time_grid is 0 and the last entry is equal to T.\")\n",
    "        else:\n",
    "            time_grid_in = time_grid\n",
    "\n",
    "    time_grid_in = torch.flip(time_grid_in, dims=[0])\n",
    "    S = self.R.clone()\n",
    "    S_list = []\n",
    "    S_list.append(S)\n",
    "\n",
    "    for i in range(1, len(time_grid_in)):\n",
    "        dt = time_grid_in[i] - time_grid_in[i-1]\n",
    "        #Notice that here every dt is a negative value for backward scheme.\n",
    "        if self.method == \"euler\":\n",
    "            S = self.euler_step(S, dt)\n",
    "        elif self.method == \"rk4\":\n",
    "            S = self.rk4_step(S, dt)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method\")\n",
    "        S_list.append(S)\n",
    "\n",
    "    return torch.stack(S_list[::-1])\n",
    "\n",
    "def euler_step(S, dt):\n",
    "    dS = -2 * self.H.T @ S + S @ self.M @ torch.inverse(self.D) @ self.M.T @ S - self.C\n",
    "    return S + dS * dt\n",
    "\n",
    "def rk4_step(self, S, dt):\n",
    "    def riccati_derivative(S):\n",
    "        return -2 * self.H.T @ S + S @ self.M @ torch.inverse(self.D) @ self.M.T @ S - self.C\n",
    "    k1 = riccati_derivative(S)\n",
    "    k2 = riccati_derivative(S + 0.5 * dt * k1)\n",
    "    k3 = riccati_derivative(S + 0.5 * dt * k2)\n",
    "    k4 = riccati_derivative(S + dt * k3)\n",
    "\n",
    "    return S + (k1 + 2*k2 + 2*k3 + k4) * dt / 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
